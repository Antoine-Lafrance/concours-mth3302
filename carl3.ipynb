{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTH3302 - Méthodes probabilistes et statistiques pour I.A.\n",
    "#### Polytechnique Montréal\n",
    "### Projet A2024\n",
    "----\n",
    "Équipe T - TODO\n",
    "### Objectif\n",
    "Prédiction de **la consommation en carburant de voitures récentes**.\n",
    "\n",
    "### Données\n",
    "Le jeu de données contient pour presque 400 véhicule, la consommation moyenne en L/100km, l'année de frabrication, le type de véhicule, le nombre de cylindre, cylindree, la transmission et la boite.\n",
    "\n",
    "- `train.csv` est l'ensemble d'entraînement\n",
    "- `test.csv` est l'ensemble de test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des librairies utilisées dans le calepin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// TODO: à enlever à la fin:\n",
    "\n",
    "Pour importer librairies:\n",
    "using Pkg\n",
    "Pkg.add([\"CSV\", \"DataFrames\", \"Combinatorics\", \"Gadfly\", \"Distributions\"], ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1711,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pkg; Pkg.add(\"Plots\")\n",
    "# import Pkg; Pkg.add(\"DecisionTree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1712,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, LinearAlgebra, DecisionTree,Random, Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1713,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "standardize_data (generic function with 1 method)"
      ]
     },
     "execution_count": 1713,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function standardize(data)\n",
    "    return (data .- mean(data)) ./ std(data)\n",
    "end\n",
    "\n",
    "function standardize_data(data)\n",
    "    stddata = deepcopy(data)\n",
    "   for col in names(stddata)\n",
    "        if eltype(stddata[!, col]) <: Number && col != \"id\"\n",
    "            stddata[!, col] = standardize(stddata[!, col])\n",
    "        end\n",
    "    end\n",
    "    return stddata\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1714,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encode_data (generic function with 1 method)"
      ]
     },
     "execution_count": 1714,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function encode(data, column)\n",
    "    for c in unique(data[!, column])\n",
    "        data[!, Symbol(c)] = ifelse.(data[!, column] .== c, 1, 0)\n",
    "    end\n",
    "    return data\n",
    "end\n",
    "\n",
    "function encode_data(data)\n",
    "    encoded_data = deepcopy(data)\n",
    "    encoded_data = encode(encoded_data, :general_type)\n",
    "    # encoded_data = encode(encoded_data, :annee)\n",
    "    # encoded_data = encode(encoded_data, :type)\n",
    "    encoded_data = encode(encoded_data, :transmission)\n",
    "    encoded_data = encode(encoded_data, :boite)\n",
    "    return encoded_data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1715,
   "metadata": {},
   "outputs": [],
   "source": [
    "# faire une méthode pour les outliers\n",
    "\n",
    "# code pas tester:\n",
    "# function remove_outliers(data)\n",
    "#     return data[(abs.(zscore(data)) .< 3) .| isnan.(zscore(data)), :]\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "removeRows (generic function with 1 method)"
      ]
     },
     "execution_count": 1716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function removeRows(data)\n",
    "    return select!(data, Not([:type, :transmission, :boite, :general_type, :weight, :volume_gaz]))\n",
    "    # return select!(data, Not([:annee]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1717,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_rows (generic function with 1 method)"
      ]
     },
     "execution_count": 1717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function add_rows(data)\n",
    "    data[!,:volume_gaz] = data[!,:nombre_cylindres] .* data[!,:cylindree]\n",
    "\n",
    "    # https://www.insurancenavy.com/average-car-weight/\n",
    "    # https://www.auto-tests.com/fr/lightest-weight/Wagon/all/\n",
    "    weight_dict = Dict(\"voiture_moyenne\" => 3300, \"VUS_petit\" => 3500, \"voiture_compacte\" => 2800, \"voiture_deux_places\" => 2800, \"voiture_minicompacte\" => 1500, \"VUS_standard\" => 5000, \"monospace\" => 4500, \"voiture_sous_compacte\" => 2600, \"camionnette_petit\" => 4200, \"break_petit\" => 2640, \"voiture_grande\" => 4400, \"camionnette_standard\" => 4700, \"break_moyen\" => 3300)\n",
    "    data[!, :weight] = [weight_dict[t] for t in data[!, :type]]\n",
    "\n",
    "    general_type_dict = Dict(\"voiture_moyenne\" => \"voiture\", \"VUS_petit\" => \"VUS\", \"voiture_compacte\" => \"voiture\", \"voiture_deux_places\" => \"voiture\", \"voiture_minicompacte\" => \"voiture\", \"VUS_standard\" => \"VUS\", \"monospace\" => \"camionnette\", \"voiture_sous_compacte\" => \"voiture\", \"camionnette_petit\" => \"camionnette\", \"break_petit\" => \"break\", \"voiture_grande\" => \"voiture\", \"camionnette_standard\" => \"camionnette\", \"break_moyen\" => \"break\")\n",
    "    data[!, :general_type] = [general_type_dict[t] for t in data[!, :type]]\n",
    "    \n",
    "    # display(plot(data, x=:general_type, y=:consommation, color=:type))\n",
    "    # println(combine(groupby(data, :type), nrow => :count))\n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1718,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getStandardEncodedData (generic function with 1 method)"
      ]
     },
     "execution_count": 1718,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function getStandardEncodedData(data)\n",
    "    data_copy = deepcopy(data)\n",
    "    standardised_data = add_rows(data_copy)\n",
    "    standardised_data = standardize_data(data_copy)\n",
    "    standardised_data = encode_data(standardised_data)\n",
    "    standardised_data = removeRows(standardised_data)\n",
    "    \n",
    "    # print(standardised_data)\n",
    "    return standardised_data\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1719,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse (generic function with 1 method)"
      ]
     },
     "execution_count": 1719,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rmse(y, ychap)\n",
    "    return sqrt(mean((ychap .- y).^2))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rsquared (generic function with 1 method)"
      ]
     },
     "execution_count": 1720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rsquared(y, ychap)\n",
    "    ss_total = sum((y .- mean(y)).^2)\n",
    "    ss_res = sum((y .- ychap).^2)\n",
    "    return ss_res / ss_total\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_test_split (generic function with 3 methods)"
      ]
     },
     "execution_count": 1721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_test_split(data, test_size=0.2, shuffle=true)\n",
    "    n = size(data, 1)\n",
    "    test_size = floor(Int, n * test_size)\n",
    "    \n",
    "    if shuffle\n",
    "        indices = randperm(n)\n",
    "    else\n",
    "        indices = 1:n\n",
    "    end\n",
    "    \n",
    "    test_indices = indices[1:test_size]\n",
    "    train_indices = indices[test_size+1:end]\n",
    "    \n",
    "    train_data = data[train_indices, :]\n",
    "    test_data = data[test_indices, :]\n",
    "    \n",
    "    return train_data, test_data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-element Vector{Float64}:\n",
       " 13.8358823529412\n",
       "  9.80041666666667\n",
       " 11.7605\n",
       " 13.0672222222222\n",
       "  7.3503125\n",
       "  7.58741935483871\n",
       " 11.2004761904762\n",
       " 14.700625\n",
       " 12.3794736842105\n",
       " 10.6913636363636\n",
       "  9.4084\n",
       " 15.6806666666667\n",
       "  8.71148148148148\n",
       "  8.11068965517241\n",
       " 10.2265217391304\n",
       "  7.84033333333333\n",
       "  8.40035714285714\n",
       "  9.04653846153846\n",
       " 16.8007142857143\n",
       "  6.91794117647059\n",
       "  6.35702702702703\n",
       "  4.52326923076923\n",
       "  7.12757575757576\n",
       "  4.90020833333333\n",
       "  6.53361111111111"
      ]
     },
     "execution_count": 1722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData = CSV.read(\"./data/train.csv\", DataFrame)\n",
    "testData = CSV.read(\"./data/test.csv\", DataFrame)\n",
    "trainData.consommation = parse.(Float64,replace.(trainData.consommation, \",\" => \".\"))\n",
    "trainData.cylindree = parse.(Float64,replace.(trainData.cylindree, \",\" => \".\"))\n",
    "testData.cylindree = parse.(Float64,replace.(testData.cylindree, \",\" => \".\"))\n",
    "\n",
    "\n",
    "COMSOMMATION_MEAN = mean(trainData.consommation)\n",
    "COMSOMMATION_STD = std(trainData.consommation)\n",
    "trainData[!, :id] = 1:nrow(trainData)\n",
    "testData[!, :id] = 1:nrow(testData)\n",
    "\n",
    "possibles = unique(trainData.consommation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1723,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function evaluate_rmse()\n",
    "#     data = getStandardEncodedData(trainData)\n",
    "#     nrange = 1000\n",
    "#     n = 0\n",
    "#     for i in range(0, 1, length=nrange)\n",
    "#         n += regression(data, 0.05)[1]\n",
    "#     end\n",
    "#     print(\"average rmse for regression: \", n/nrange, \"\\n\")\n",
    "\n",
    "#     n = 0\n",
    "#     for i in range(0, 1, length=nrange)\n",
    "#         n += ridge_regression(data, 0.1, 0.05)[1]\n",
    "#     end\n",
    "#     print(\"average rmse for ridge: \", n/nrange, \"\\n\")\n",
    "\n",
    "#     n = 0\n",
    "#     for i in range(0, 1, length=nrange)\n",
    "#         n += svd_regression(data, 0.05)[1]\n",
    "#     end\n",
    "#     print(\"average rmse for svd: \", n/nrange, \"\\n\")\n",
    "\n",
    "#     nrange = 1000\n",
    "#     n = 0\n",
    "#     for i in range(0, 1, length=nrange)\n",
    "#         n += polynomial_regression(data,2, 0.05)[1]\n",
    "#     end\n",
    "#     print(\"average rmse for polynomial regression: \", n/nrange, \"\\n\")\n",
    "\n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1724,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# function predict(data, beta)\n",
    "#     return (Matrix(data[:, Not(:consommation, :id)]) * beta)\n",
    "# end\n",
    "\n",
    "# function destandardize(data)\n",
    "#     return (data .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "# end\n",
    "\n",
    "# function predict_and_destandardize(data, beta)\n",
    "#     return destandardize(predict(data, beta))\n",
    "# end\n",
    "\n",
    "\n",
    "\n",
    "# function find_mistakes(data_to_predict, beta, col)\n",
    "#     prediction = (Matrix(data_to_predict[:, Not(:consommation, :id)]) * beta)\n",
    "#     prediction = (prediction .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "#     data_to_predict[!,:consommation] = data_to_predict[!,:consommation] .* COMSOMMATION_STD .+ COMSOMMATION_MEAN\n",
    "\n",
    "#     idtrain = 1:size(prediction, 1)\n",
    "\n",
    "#     base_data_of_predicted = innerjoin(data_to_predict, trainData, on=:id, makeunique=true)\n",
    "\n",
    "#     scatter(idtrain, prediction)\n",
    "#     scatter!(idtrain, base_data_of_predicted[!,:consommation])\n",
    "\n",
    "\n",
    "#     difference = prediction - base_data_of_predicted[!,:consommation]\n",
    "#     base_data_of_predicted[!, :difference] = difference\n",
    "#     diff_cutoff = 1\n",
    "#     high_diff_rows = base_data_of_predicted[abs.(difference) .> diff_cutoff, :]\n",
    "\n",
    "#     grouped_normal = combine(groupby(base_data_of_predicted, col), nrow => :count)\n",
    "\n",
    "#     grouped_high_diff = combine(groupby(high_diff_rows, col), nrow => :count)\n",
    "\n",
    "#     grouped_high_diff[!, :total_diff] = combine(groupby(high_diff_rows, col), :difference => (x -> sum(abs.(x))) => :total_diff)[:, :total_diff]\n",
    "\n",
    "#     max_diff = combine(groupby(high_diff_rows, col), :difference => (x -> maximum(abs.(x))) => :max_diff)\n",
    "\n",
    "#     grouped_high_diff = leftjoin(grouped_high_diff, max_diff, on=col)\n",
    "#     grouped_high_diff[!, :average_diff] = combine(groupby(high_diff_rows, col), :difference => (x -> mean(abs.(x))) => :average_abs_diff)[:, :average_abs_diff]\n",
    "\n",
    "#     grouped_high_diff[!, :rmse] = combine(groupby(high_diff_rows, col), :difference => (x -> sqrt(mean(x.^2))) => :rmse)[:, :rmse]\n",
    "#     grouped_normal[!, :rmse] = combine(groupby(base_data_of_predicted, col), :difference => (x -> sqrt(mean(x.^2))) => :rmse)[:, :rmse]\n",
    "\n",
    "#     percentage_high_diff = leftjoin(grouped_high_diff, grouped_normal, on=col, makeunique=true)\n",
    "#     percentage_high_diff[!, :percentage] = percentage_high_diff[!, :count] ./ percentage_high_diff[!, :count_1] .* 100\n",
    "#     percentage_high_diff = sort(percentage_high_diff, :percentage, rev=true)\n",
    "\n",
    "#     println(\"Percentage of data by \", col,\" with difference higher than 1: \")\n",
    "#     println(percentage_high_diff[:, [col, :percentage, :count, :count_1, :total_diff, :max_diff, :average_diff, :rmse]])\n",
    "\n",
    "#     grouped_normal = sort(grouped_normal, :rmse, rev=true)\n",
    "\n",
    "#     println(grouped_normal[:, [col, :count, :rmse]])\n",
    "# end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1725,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rmseval, betatrain, traindata, testpredictdata = regression(data, 0.2)\n",
    "# find_mistakes(testpredictdata, betatrain, :annee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1726,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "format_file (generic function with 1 method)"
      ]
     },
     "execution_count": 1726,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# beta = ridge_regression(data, 10, 0.0)[2]\n",
    "# function remise_regression(beta)\n",
    "#     test_data = getStandardEncodedData(testData)\n",
    "#     X_test = Matrix(test_data[!,Not(:id)])\n",
    "#     ychap =  X_test * beta\n",
    "#     ychap = (ychap .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "#     remise(ychap)\n",
    "# end\n",
    "function remise(prediction)\n",
    "    id = 1:150\n",
    "    df_pred = DataFrame(id=id, consommation=prediction)\n",
    "\n",
    "   format_file(df_pred)\n",
    "end\n",
    "\n",
    "function format_file(predictions)\n",
    "    println(predictions)\n",
    "    current_time = Dates.format(now(), \"yyyy-mm-dd_HH-MM-SS\")\n",
    "    file_name = \"benchmark_\" * current_time * \".csv\"\n",
    "    CSV.write(\"./soumissions_potentielles/\" *file_name, predictions)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1727,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forest_predict (generic function with 1 method)"
      ]
     },
     "execution_count": 1727,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# findnearest(A::Vector{Float64},t::Float64) = A[findmin(broadcast(abs,A.-t))[2]]\n",
    "\n",
    "function findnearest(A::Vector{Float64},t::Float64)\n",
    "    nearest_value = A[1]\n",
    "    smallest_diff = abs(A[1] - t)\n",
    "    for value in A\n",
    "        diff = abs(value - t)\n",
    "        if diff < smallest_diff\n",
    "            smallest_diff = diff\n",
    "            nearest_value = value\n",
    "        end\n",
    "    end\n",
    "    if smallest_diff > 0.3\n",
    "        # println(\"Warning: the nearest value is \", nearest_value, \" the value was \", t,\" with a difference of \", smallest_diff)\n",
    "    end\n",
    "    return nearest_value\n",
    "    \n",
    "end\n",
    "\n",
    "function forest(data)\n",
    "    train, test= train_test_split(data)\n",
    "\n",
    "    X_train =  Matrix(train[:, Not(:consommation, :id)])\n",
    "    y_train = train.consommation\n",
    "    X_test = Matrix(test[:, Not(:consommation, :id)])\n",
    "    y_test = test.consommation\n",
    "\n",
    "\n",
    "    model = RandomForestRegressor(n_subfeatures=12, n_trees=1000,min_samples_leaf=1,min_purity_increase=0.0, max_depth=10, min_samples_split=6)\n",
    "    DecisionTree.fit!(model, X_train, y_train)\n",
    "    y_pred = DecisionTree.predict(model, X_test)\n",
    "\n",
    "    train_consommation = (test.consommation * COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "    y_pred = (y_pred * COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "    # println(size(y_pred))\n",
    "    # println(unique(y_pred))\n",
    "    # println(size(unique(y_pred)))\n",
    "    #println(y_pred)\n",
    "    # y_pred = map(x -> findnearest(possibles,x),y_pred)\n",
    "    # println(y_pred_adjusted)\n",
    "    # println(y_pred)\n",
    "    # println(test.consommation)\n",
    "    return sqrt(mean((y_pred - train_consommation).^2)), y_pred\n",
    "end\n",
    "\n",
    "function forest_predict(train, predict)\n",
    "    X_train =  Matrix(train[:, Not(:consommation)])\n",
    "    y_train = train.consommation\n",
    "    X_predict = Matrix(predict[:, Not(:id)])\n",
    "    # println(X_train)\n",
    "    # println(y_train)\n",
    "    # println(X_predict)\n",
    "\n",
    "    model = RandomForestRegressor(n_subfeatures=12, n_trees=1000,min_samples_leaf=1,min_purity_increase=0.0, max_depth=10, min_samples_split=6)\n",
    "    DecisionTree.fit!(model, X_train, y_train)\n",
    "    y_pred = DecisionTree.predict(model, X_predict)\n",
    "\n",
    "    y_pred = (y_pred * COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "    # y_pred = map(x -> findnearest(possibles,x),y_pred)\n",
    "    # println(y_pred)\n",
    "    return y_pred\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1728,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_rmse (generic function with 1 method)"
      ]
     },
     "execution_count": 1728,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evaluate_rmse(data)\n",
    "    n = 0\n",
    "    for i in 1:100\n",
    "        val = forest(data)[1]\n",
    "        n += val\n",
    "        # println(val)\n",
    "    end\n",
    "    println(n/100)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1729,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict_with_dups (generic function with 1 method)"
      ]
     },
     "execution_count": 1729,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function find_duplicates(data)\n",
    "#     data_without_consommation = select(data, Not(:consommation, :id, :annee))\n",
    "#     # println(data_without_consommation)\n",
    "#     return data[findall(x -> count(==(x), eachrow(data_without_consommation)) > 1, eachrow(data_without_consommation)), :]\n",
    "# end\n",
    "\n",
    "function get_unique_data(data)\n",
    "    data_without_consommation = select(data, Not(:consommation, :id, :annee))\n",
    "\n",
    "   \n",
    "    unique_data = combine(groupby(data, names(data_without_consommation)), :consommation => mean)\n",
    "    rename!(unique_data, :consommation_mean => :consommation)\n",
    "    return unique_data\n",
    "end\n",
    "\n",
    "function find_pairs(data_train, data_predict)\n",
    "    train_data_without_consommation = select(data_train, Not(:consommation))\n",
    "    predict_data_without_consommation = select(data_predict, Not( :annee))\n",
    "\n",
    "    common_values = innerjoin(data_train, predict_data_without_consommation, on=names(train_data_without_consommation))\n",
    "\n",
    "    println(common_values.id)\n",
    "    # common_values = intersect(data_train, data_predict)\n",
    "    return common_values\n",
    "end\n",
    "\n",
    "function find_differents(data_train, data_predict)\n",
    "    different_values = antijoin(data_predict, data_train, on=[\"type\", \"nombre_cylindres\", \"cylindree\", \"transmission\", \"boite\"])\n",
    "    println(different_values.id)\n",
    "    return different_values\n",
    "    \n",
    "end\n",
    "\n",
    "function predict_with_dups(data_train, data_predict)\n",
    "    pairs = find_pairs(data_train, data_predict)\n",
    "    pairs = select(pairs, [:id, :consommation])\n",
    "    different_values = find_differents(data_train, data_predict)\n",
    "\n",
    "    # println(data_train)\n",
    "\n",
    "    trainDataStandard = getStandardEncodedData(data_train)\n",
    "    predictDataStandard = getStandardEncodedData(different_values)\n",
    "    # println(predictDataStandard)\n",
    "    different_values[!, :consommation] = forest_predict(trainDataStandard,predictDataStandard)\n",
    "    # println(different_values)\n",
    "    different_values = select(different_values, [:id, :consommation])\n",
    "    prediction = vcat(pairs, different_values)\n",
    "    prediction = sort(prediction, :id)\n",
    "    # println(prediction)\n",
    "    return prediction\n",
    "end\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 6, 7, 8, 9, 13, 14, 15, 16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 46, 47, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 103, 104, 105, 106, 108, 109, 111, 113, 114, 116, 117, 120, 121, 122, 123, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150]\n",
      "[5, 10, 11, 12, 17, 18, 19, 20, 39, 42, 45, 48, 49, 52, 68, 69, 70, 72, 88, 98, 99, 107, 110, 112, 115, 118, 119, 124, 125, 132]\n",
      "\u001b[1m150×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m id    \u001b[0m\u001b[1m consommation \u001b[0m\n",
      "     │\u001b[90m Int64 \u001b[0m\u001b[90m Float64      \u001b[0m\n",
      "─────┼─────────────────────\n",
      "   1 │     1       8.11069\n",
      "   2 │     2       7.59532\n",
      "   3 │     3       8.66848\n",
      "   4 │     4       8.71148\n",
      "   5 │     5      11.6174\n",
      "   6 │     6      13.8359\n",
      "   7 │     7      13.8359\n",
      "   8 │     8      10.2265\n",
      "   9 │     9      10.9459\n",
      "  10 │    10      11.2175\n",
      "  11 │    11      11.2175\n",
      "  12 │    12      11.839\n",
      "  13 │    13       9.30079\n",
      "  14 │    14      10.3044\n",
      "  15 │    15       8.11069\n",
      "  16 │    16      11.5738\n",
      "  17 │    17      11.4529\n",
      "  18 │    18      11.4529\n",
      "  19 │    19      11.5375\n",
      "  20 │    20      11.5375\n",
      "  21 │    21      13.8359\n",
      "  22 │    22      13.0672\n",
      "  23 │    23      13.0672\n",
      "  24 │    24      13.8359\n",
      "  25 │    25      13.0672\n",
      "  26 │    26      14.7006\n",
      "  27 │    27      13.0672\n",
      "  28 │    28      14.7006\n",
      "  29 │    29      12.6546\n",
      "  30 │    30      10.5223\n",
      "  31 │    31      11.9668\n",
      "  32 │    32       8.66848\n",
      "  33 │    33      10.3953\n",
      "  34 │    34      11.9668\n",
      "  35 │    35       9.04654\n",
      "  36 │    36       7.58742\n",
      "  37 │    37      10.5223\n",
      "  38 │    38      10.5223\n",
      "  39 │    39       8.41161\n",
      "  40 │    40       9.04654\n",
      "  41 │    41      13.0672\n",
      "  42 │    42       9.67326\n",
      "  43 │    43      10.1294\n",
      "  44 │    44       7.58567\n",
      "  45 │    45       8.82832\n",
      "  46 │    46      11.2107\n",
      "  47 │    47      10.3953\n",
      "  48 │    48      10.1483\n",
      "  49 │    49       8.77555\n",
      "  50 │    50      14.4124\n",
      "  51 │    51      12.3795\n",
      "  52 │    52      10.2971\n",
      "  53 │    53       4.90021\n",
      "  54 │    54      13.0672\n",
      "  55 │    55      10.5223\n",
      "  56 │    56      10.5223\n",
      "  57 │    57      11.2005\n",
      "  58 │    58      12.838\n",
      "  59 │    59       8.96277\n",
      "  60 │    60       8.71148\n",
      "  61 │    61       8.87901\n",
      "  62 │    62       9.61229\n",
      "  63 │    63      10.0135\n",
      "  64 │    64      10.0135\n",
      "  65 │    65       8.79525\n",
      "  66 │    66      11.0378\n",
      "  67 │    67      11.0378\n",
      "  68 │    68      11.9607\n",
      "  69 │    69      12.1739\n",
      "  70 │    70      11.9607\n",
      "  71 │    71      10.2459\n",
      "  72 │    72      10.8531\n",
      "  73 │    73      10.2459\n",
      "  74 │    74      10.1924\n",
      "  75 │    75      10.2459\n",
      "  76 │    76      12.3795\n",
      "  77 │    77      15.6807\n",
      "  78 │    78      15.6807\n",
      "  79 │    79      10.3953\n",
      "  80 │    80      11.9668\n",
      "  81 │    81      11.7801\n",
      "  82 │    82       9.30079\n",
      "  83 │    83       9.64327\n",
      "  84 │    84       8.71148\n",
      "  85 │    85       8.71148\n",
      "  86 │    86       8.78864\n",
      "  87 │    87      10.1294\n",
      "  88 │    88      10.9597\n",
      "  89 │    89       8.12035\n",
      "  90 │    90       8.11713\n",
      "  91 │    91      10.2265\n",
      "  92 │    92      13.1077\n",
      "  93 │    93       8.18793\n",
      "  94 │    94       8.12035\n",
      "  95 │    95       8.12035\n",
      "  96 │    96       4.52327\n",
      "  97 │    97       4.52327\n",
      "  98 │    98       9.48677\n",
      "  99 │    99      10.7072\n",
      " 100 │   100      10.1294\n",
      " 101 │   101       8.71148\n",
      " 102 │   102      11.4041\n",
      " 103 │   103       9.04654\n",
      " 104 │   104       8.78864\n",
      " 105 │   105       8.40036\n",
      " 106 │   106       8.79525\n",
      " 107 │   107       9.00802\n",
      " 108 │   108      10.1294\n",
      " 109 │   109      11.2005\n",
      " 110 │   110      12.2752\n",
      " 111 │   111       8.78864\n",
      " 112 │   112      10.6988\n",
      " 113 │   113       8.11069\n",
      " 114 │   114       9.30079\n",
      " 115 │   115      10.4711\n",
      " 116 │   116       8.75935\n",
      " 117 │   117       7.93627\n",
      " 118 │   118      10.8359\n",
      " 119 │   119      12.4532\n",
      " 120 │   120       9.80042\n",
      " 121 │   121       9.4084\n",
      " 122 │   122      10.2265\n",
      " 123 │   123       8.71148\n",
      " 124 │   124      10.8296\n",
      " 125 │   125      10.8296\n",
      " 126 │   126      10.9459\n",
      " 127 │   127       7.53425\n",
      " 128 │   128      10.1294\n",
      " 129 │   129      12.9347\n",
      " 130 │   130       8.75935\n",
      " 131 │   131       8.40036\n",
      " 132 │   132      10.7007\n",
      " 133 │   133       7.53425\n",
      " 134 │   134      14.7006\n",
      " 135 │   135      10.1294\n",
      " 136 │   136       9.53164\n",
      " 137 │   137      10.9459\n",
      " 138 │   138       7.53425\n",
      " 139 │   139       7.35031\n",
      " 140 │   140      11.7605\n",
      " 141 │   141      12.6546\n",
      " 142 │   142      10.1294\n",
      " 143 │   143       9.30079\n",
      " 144 │   144       7.53425\n",
      " 145 │   145       8.60777\n",
      " 146 │   146       8.87901\n",
      " 147 │   147      11.7605\n",
      " 148 │   148      10.9173\n",
      " 149 │   149       7.58742\n",
      " 150 │   150       7.93627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"./soumissions_potentielles/benchmark_2024-11-30_12-57-51.csv\""
      ]
     },
     "execution_count": 1730,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function main()\n",
    "    # println(find_duplicates(trainData))\n",
    "    uniqueD = get_unique_data(trainData)\n",
    "    # find_pairs(uniqueD, testData)\n",
    "\n",
    "    # print(uniqueD)\n",
    "    # print(trainData[!, Not(:id, :annee)])\n",
    "\n",
    "    # println(uniqueD)\n",
    "    predict_with_dups(trainData[!, Not(:id, :annee)], testData)\n",
    "    # format_file(predict_with_dups(uniqueD, testData))\n",
    "    # uniqueD[!,:volume_gaz] = uniqueD[!,:nombre_cylindres] .* uniqueD[!,:cylindree]\n",
    "    # uniqueD\n",
    "    \n",
    "    # display(plot(x=uniqueD.cylindree, y=uniqueD.consommation, color=uniqueD.type))\n",
    "    # scatter(uniqueD.volume_gaz, uniqueD.consommation, zcolor=uniqueD.type)\n",
    "    # trainDataStandard = getStandardEncodedData(trainData)\n",
    "\n",
    "    # predictDataStandard = getStandardEncodedData(testData)\n",
    "    # evaluate_rmse(trainDataStandard)\n",
    "    # forest_predict(trainDataStandard,predictDataStandard)\n",
    "end\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1731,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for type in unique(trainData.type)\n",
    "#     println(type)\n",
    "#     data_type = trainData[trainData.type .== type, :]\n",
    "#     println(combine(groupby(data_type, :transmission), :consommation => mean, :volume_gaz => mean, nrow => :nrow))\n",
    "#     println()\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1732,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for type in unique(trainData.type)\n",
    "#     println(type)\n",
    "#     data_type = trainData[trainData.type .== type, :]\n",
    "#     display(plot(x=data_type.volume_gaz, y=data_type.consommation))\n",
    "#     println()\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des données"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
