{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concours MTH3302\n",
    "#### Polytechnique Montréal\n",
    "### Projet A2024\n",
    "----\n",
    "### Objectif\n",
    "Prédire **la `consommation` en carburant de voitures récentes**.\n",
    "\n",
    "### Données\n",
    "Le jeu de données contient pour presque 400 véhicule, la consommation moyenne en L/100km, l'année de frabrication, le type de véhicule, le nombre de cylindre, cylindree, la transmission et la boite.\n",
    "\n",
    "- `train.csv` est l'ensemble d'entraînement\n",
    "- `test.csv` est l'ensemble de test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des librairies utilisées dans le calepin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pkg; Pkg.add(\"Combinatorics\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, Combinatorics, Random, LinearAlgebra, DecisionTree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier fichier est l'ensemble des données pour l'entrainement, il contient l'année, le type, le nombre_cylindres, la cylindree, la transmission, la boite, la consommation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainData = CSV.read(\"./data/train.csv\", DataFrame)\n",
    "trainData.consommation = parse.(Float64,replace.(trainData.consommation, \",\" => \".\"))\n",
    "trainData.cylindree = parse.(Float64,replace.(trainData.cylindree, \",\" => \".\"))\n",
    "trainData[!, :id] = 1:nrow(trainData)\n",
    "first(trainData, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le deuxième fichier est l'ensemble des données pour le test, il contient l'année, le type, le nombre_cylindres, la cylindree, la transmission, la boite. Ici il n'a pas la consommation car il s'agit de la variable d'intérêt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = CSV.read(\"./data/test.csv\", DataFrame)\n",
    "first(testData, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de l’étape d’exploration des données, notre objectif principal était de mieux comprendre les caractéristiques disponibles afin d’évaluer leur pertinence pour la prédiction de la `consommation` en carburant. Nous avons adopté une approche intuitive, en nous appuyant sur nos connaissances de base concernant les véhicules et leur consommation, pour repérer les tendances et des relations potentielles entre les variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement donnée pour l'exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargeons les données pour l'exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataExploration = CSV.read(\"./data/train.csv\", DataFrame)\n",
    "testDataExploration = CSV.read(\"./data/test.csv\", DataFrame)\n",
    "first(trainDataExploration, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions s'il y a des données manquantes dans l'ensemble d'entrainement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function missing_data(data)\n",
    "    missing_counts = []\n",
    "    for col_name in names(data)\n",
    "        missing_count = 0\n",
    "        for value in data[:, col_name]\n",
    "            if ismissing(value)\n",
    "                missing_count += 1\n",
    "            end\n",
    "        end\n",
    "        push!(missing_counts, missing_count) \n",
    "    end\n",
    "    return missing_counts\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data(trainDataExploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data(testDataExploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons constater qu'il n'y a pas de données manquantes dans les données fournies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion des données : préparation des colonnes pour l'analyse et l'évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étant donné que les colonnes `cylindree` et `consommation` sont actuellement définies comme `String3` et `String31` respectivement, il est nécessaire de modifier leur type en `Float64` dans les deux ensembles de données afin de pouvoir les analyser correctement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataExploration.consommation = parse.(Float64,replace.(trainDataExploration.consommation, \",\" => \".\"))\n",
    "trainDataExploration.cylindree = parse.(Float64,replace.(trainDataExploration.cylindree, \",\" => \".\"))\n",
    "first(trainDataExploration, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de nouvelles variables explicatives : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour enrichir notre analyse et améliorer les performances du modèle, nous avons ajouté de nouvelles variables explicatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `volume_gaz`\n",
    "Cette variable est calculée comme le produit du nombre de cylindres et de la cylindrée du moteur. Elle reflète la capacité totale de déplacement du moteur, ce qui pourrait avoir une influence directe sur la consommation de carburant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataExploration[!,:volume_gaz] = trainDataExploration[!,:nombre_cylindres] .* trainDataExploration[!,:cylindree]\n",
    "first(trainDataExploration, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `weight`\n",
    "À compléter\n",
    "... https://www.insurancenavy.com/average-car-weight/\n",
    " https://www.auto-tests.com/fr/lightest-weight/Wagon/all/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = Dict(\"voiture_moyenne\" => 3300, \"VUS_petit\" => 3500, \"voiture_compacte\" => 2800, \"voiture_deux_places\" => 2800, \"voiture_minicompacte\" => 1500, \"VUS_standard\" => 5000, \"monospace\" => 4500, \"voiture_sous_compacte\" => 2600, \"camionnette_petit\" => 4200, \"break_petit\" => 2640, \"voiture_grande\" => 4400, \"camionnette_standard\" => 4700, \"break_moyen\" => 3300)\n",
    "trainDataExploration[!, :weight] = [weight_dict[t] for t in trainDataExploration[!, :type]]\n",
    "first(trainDataExploration, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche de relation entre les variables explicatives et la variable d'intérêt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysons maintenant chacune des variables de l'ensemble d'entraînement en fonction de notre variable cible, la `consommation`. Cette étape vise à détecter les relations potentielles entre les variables. Concrètement, nous traçons des graphiques de `consommation` en fonction de différentes variables, telles que : `annee`, `type`, `nombre_cylindres`, `cylindree`, `transmission`, `boite`, `volume_gaz` et `weight`. Nous faisons cela afin de détecter une tendance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [:annee, :type, :nombre_cylindres, :cylindree, :transmission, :boite, :volume_gaz, :weight]\n",
    "\n",
    "plots = [\n",
    "    Gadfly.plot(\n",
    "        trainDataExploration,\n",
    "        x=var,\n",
    "        y=:consommation,\n",
    "        Geom.point,\n",
    "        Guide.xlabel(string(var)),\n",
    "        Guide.ylabel(\"consommation\")\n",
    "    ) for var in variables\n",
    "]\n",
    "\n",
    "set_default_plot_size(35cm, 35cm)\n",
    "p = reshape(plots, (4,2))\n",
    "gridstack(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valeurs_nombre_cylindres = unique(trainDataExploration[:,:nombre_cylindres])\n",
    "println(\"Valeurs distinctes de la colonne :nombre_cylindres : \", valeurs_nombre_cylindres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse des graphiques ci-dessus:\n",
    "\n",
    "Pour les variables explicatives suivantes en fonction de la consommation:\n",
    "- `annee` : La distribution de la consommation selon les années semble relativement homogène. On observe cependant une légère diminution de la consommation en 2020 et 2021, probablement attribuable aux effets de la pandémie. Par conséquent, il apparaît que cette variable n'entretient pas de relation linéaire évidente avec la consommation. Cette variable n'aura donc probablement pas d'influence sur la consommation.\n",
    "\n",
    "- `type`: Pour certains types de véhicules, la quantité de données disponibles est insuffisante, ce qui complique une évaluation fiable et précise de leur impact sur la consommation. Cette limitation justifie la nécessité de mener une analyse complémentaire dédiée à cette variable, comme détaillé dans la prochaine section intitulée \"Analyse par type de véhicule\". Pour le type voiture_minicompacte, on observe une valeur de consommation nettement plus élevée, ce qui suggère la présence possible de données aberrantes ainsi on va effectuer l'analyse des données aberrantes.\n",
    "\n",
    "- `nombre_cylindres`: On observe que cette variable peut prendre 7 valeurs distinctes : [3, 4, 5, 6, 8, 10, 12]. Parmi celles-ci, deux valeurs (5 et 12) n'ont chacune qu'une seule donnée de consommation, et une autre valeur (10) en a seulement deux. De plus, on remarque une tendance où l'augmentation du nombre de cylindres est associée à une augmentation de la consommation, suggérant une possible relation linéaire entre ces deux variables. \n",
    "\n",
    "- `cylindree` : On remarque une tendance où l'augmentation de la cylindree est associée à une augmentation de la consommation, suggérant une possible relation linéaire entre ces deux variables.\n",
    "\n",
    "- `transmission`: Les transmissions intégrale, propulsion et 4x4 présentent une distribution de consommation relativement similaire. En revanche, la transmission traction semble afficher une tendance à une consommation inférieure par rapport aux autres.\n",
    "\n",
    "- `boite`: Le type de boîte de vitesses ne semble pas influencer significativement la consommation, car la distribution de la consommation pour les boîtes automatiques est globalement similaire à celle des boîtes manuelles.\n",
    "\n",
    "- `volume_gaz` : La relation entre les deux variables semble linéaire. Cependant, on remarque qu'il y a beaucoup plus de données pour des volumes faibles que pour des volumes élevés.\n",
    "\n",
    "- `weight`: Étant donné que le poids prend en compte les différents types de véhicules, il est difficile d'analyser une relation directe entre le poids et la consommation. Malgré ça, pour le moment on ne voit pas de relation linéaire entre les deux variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse par `type` de véhicule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous poursuivons l'exploration en examinant les données par `type`. Cette étape vise à identifier des comportements spécifiques à chaque `type`. En regroupant les véhicules par transmission au sein de chaque `type`, nous calculons la `consommation` moyenne, le `volume_gaz` moyen et le nombre d'observations dans chaque groupe. Cela nous permet de mieux comprendre comment ces facteurs interagissent pour chaque `type` de véhicule et d'évaluer si le `type` ou la `transmission` influence significativement la `consommation`. Cette analyse guide ainsi la sélection des variables pertinentes pour le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type in unique(trainDataExploration.type)\n",
    "    println(type)\n",
    "    data_type = trainDataExploration[trainDataExploration.type .== type, :]\n",
    "    println(combine(groupby(data_type, :transmission), :consommation => mean, :volume_gaz => mean, nrow => :nrow))\n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "Ce qu'on en retire de ceci... à compléter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous passons maintenant à une visualisation plus détaillée. Pour chaque `type` de véhicule, nous traçons la relation entre le `volume_gaz` et la `consommation`. Cette étape vise à observer s'il existe des tendances ou des corrélations spécifiques entre ces deux variables pour chaque `type`. Ces visualisations permettent de détecter des comportements distincts ou des patrons dans les données, ce qui peut orienter la sélection des variables explicatives ou révéler des transformations nécessaires pour améliorer la précision du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "\n",
    "for type in unique(trainDataExploration.type)\n",
    "    data_type = trainDataExploration[trainDataExploration.type .== type, :]\n",
    "    push!(plots, plot(\n",
    "        x=data_type.volume_gaz,\n",
    "        y=data_type.consommation,\n",
    "        Geom.point,\n",
    "        Guide.title(\"Type: $type\"),\n",
    "        Guide.xlabel(\"Volume Gaz\"),\n",
    "        Guide.ylabel(\"Consommation\")\n",
    "    ))\n",
    "end\n",
    "\n",
    "set_default_plot_size(10cm, 10cm)\n",
    "\n",
    "for i in 1:length(plots)\n",
    "    display(plots[i])\n",
    "end "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étant donné qu'il y a très peu de données pour certains `type`, il est difficile d'analyser et d'identifier des tendances dans les graphiques ci-dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajout variable : `general_type`\n",
    "\n",
    "L'ajout de la variable `general_type` dans les données d'exploration permet de regrouper les types spécifiques de véhicules en catégories plus générales telles que \"voiture\", \"VUS\", \"camionnette\" ou \"break\". Ces catégories sont basées sur le type de carrosserie de la voiture. Cela simplifie l'analyse en réduisant la granularité de la variable `type`, qui contient de nombreuses sous-catégories. En utilisant ces regroupements, on peut mieux voir les tendances globales et réduire la complexité du modèle de prédiction, tout en conservant les différences majeures entre les groupes de véhicules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_type_dict = Dict(\"voiture_moyenne\" => \"voiture\", \"VUS_petit\" => \"VUS\", \"voiture_compacte\" => \"voiture\", \"voiture_deux_places\" => \"voiture\", \"voiture_minicompacte\" => \"voiture\", \"VUS_standard\" => \"VUS\", \"monospace\" => \"camionnette\", \"voiture_sous_compacte\" => \"voiture\", \"camionnette_petit\" => \"camionnette\", \"break_petit\" => \"break\", \"voiture_grande\" => \"voiture\", \"camionnette_standard\" => \"camionnette\", \"break_moyen\" => \"break\")\n",
    "\n",
    "trainDataExploration[!, :general_type] = [general_type_dict[t] for t in trainDataExploration[!, :type]]\n",
    "unique(trainDataExploration[!, :general_type])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinons maintenant le `volume_gaz` par rapport à la `consommation` pour chacun des `general_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "\n",
    "for general_type in unique(trainDataExploration.general_type)\n",
    "    data_type = trainDataExploration[trainDataExploration.general_type .== general_type, :]\n",
    "    push!(plots, plot(\n",
    "        x=data_type.volume_gaz,\n",
    "        y=data_type.consommation,\n",
    "        Geom.point,\n",
    "        Guide.title(\"General Type: $general_type\"),\n",
    "        Guide.xlabel(\"Volume Gaz\"),\n",
    "        Guide.ylabel(\"Consommation\")\n",
    "    ))\n",
    "end\n",
    "\n",
    "set_default_plot_size(10cm, 10cm)\n",
    "\n",
    "for i in 1:length(plots)\n",
    "    display(plots[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les graphiques ci-dessus semble montrer une tendance linéaire, où une augmentation du volume de gaz (x) semble être associée à une hausse de la consommation (y). Ainsi, la variable `general_type` pourrait être une variable explicative pertinente pour comprendre la consommation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation des variables explicatives: inclusion des variables qualitatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'encodage des variables explicatives qualitatives `general_type`, `transmission` et `boite` est essentiel afin d'être en mesure de les transformer en format numérique et de pouvoir les intégrer dans nos modèles pour effectuer la prédiction.\n",
    "\n",
    "Nous avons décidé de faire un encodage One-Hot Encoding pour représenter chaque catégorie de manière binaire (0 ou 1), ce qui permet de conserver la distinction entre les différentes catégories tout en évitant de leur attribuer une hiérarchie implicite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function encode(data, column)\n",
    "    for c in unique(data[!, column])\n",
    "        data[!, Symbol(c)] = ifelse.(data[!, column] .== c, 1, 0)\n",
    "    end\n",
    "    return data\n",
    "end\n",
    "\n",
    "function encode_data(data)\n",
    "    encoded_data = deepcopy(data)\n",
    "    encoded_data = encode(encoded_data, :general_type)\n",
    "    encoded_data = encode(encoded_data, :transmission)\n",
    "    encoded_data = encode(encoded_data, :boite)\n",
    "    return encoded_data\n",
    "end\n",
    "\n",
    "function removeRows(data)\n",
    "    return select!(data, Not([:type, :transmission, :boite, :general_type]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataExplorationEncoded = encode_data(trainDataExploration)\n",
    "removeRows(trainDataExplorationEncoded)\n",
    "first(trainDataExplorationEncoded, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse de colinéarité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colinéarité survient lorsque deux ou plusieurs variables sont fortement corrélées, ce qui peut causer des problèmes lors de l'ajustement de modèles statistiques ou d'apprentissage automatique. Plus précisément, une forte colinéarité peut :\n",
    "- Rendre difficile l'interprétation des coefficients dans un modèle.\n",
    "- TODO: Diminuer la précision des prédictions en amplifiant les erreurs.\n",
    "- Affecter la stabilité numérique des algorithmes de régression.\n",
    "\n",
    "Pour identifier les variables colinéaires, nous calculons une matrice de corrélation pour les variables numériques et repérons les paires dont la corrélation absolue dépasse un certain seuil (ici 0,8). Ceci nous guidera dans le choix des variables explicatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluer_colinearite(data, seuil)\n",
    "    numerical_data = select(data, findall(x -> eltype(x) <: Number, eachcol(data)))\n",
    "    \n",
    "    correlation_matrix = cor(Matrix(numerical_data))\n",
    "    \n",
    "    variables_colineaires = []\n",
    "    for i in 1:size(correlation_matrix, 1)\n",
    "        for j in (i + 1):size(correlation_matrix, 2)\n",
    "            if abs(correlation_matrix[i, j]) >= seuil\n",
    "                push!(variables_colineaires, (names(numerical_data)[i], names(numerical_data)[j]))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return correlation_matrix, variables_colineaires\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix, variables_colineaires = evaluer_colinearite(trainDataExplorationEncoded, 0.8)\n",
    "\n",
    "println(\"Matrice de corrélation :\")\n",
    "println(correlation_matrix)\n",
    "\n",
    "println(\"\\nPaires de variables suceptibles d'être colinéaires :\")\n",
    "for paire in variables_colineaires\n",
    "    println(paire)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analyse de colinéarité réalisée ci-dessus sur les données a permis de détecter plusieurs paires de variables susceptibles d’être fortement corrélées, notamment `nombre_cylindres`, `cylindree` et `volume_gaz`. Ce qu’on en retire est que ces variables pourraient introduire de la redondance dans les modèles prédictifs, ce qui peut affecter la stabilité et l’interprétabilité des résultats. Étant donné que la variable d'intérêt est la consommation, il serait pertinent de considérer la suppression de certaines de ces variables colinéaires afin de simplifier le modèle et éviter les problèmes liés à la multicolinéarité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calcul VIF pour ceux les paires ci-dessus??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons remarqué que, parmi les 396 données, de nombreuses possèdent les mêmes caractéristiques, c'est-à-dire que leurs variables explicatives sont identiques, à l’exception de l’année. Comme mentionné dans l’analyse des graphiques de la section \"Recherche de relations entre les variables explicatives et la variable d’intérêt\", nous n'avons pas observé de relation entre la consommation et l'année. Ainsi, nous sélectionnons toutes les colonnes de l’ensemble d’entraînement, sauf `année` et `consommation`, afin de regrouper les données ayant des caractéristiques similaires. L’objectif est ensuite de calculer la moyenne de la consommation pour chaque groupe ainsi formé. Puis de former un ensemble ayant que les données uniques. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_unique_data(data)\n",
    "    data_without_consommation = select(data, Not(:consommation, :annee))\n",
    "\n",
    "\n",
    "    unique_data = combine(groupby(data, names(data_without_consommation)), :consommation => mean)\n",
    "    rename!(unique_data, :consommation_mean => :consommation)\n",
    "    return unique_data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueTrainDataExploration = get_unique_data(trainDataExploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut obersver que nous avons maintenant 145 données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinons les relations entre la consommation et les variables explicatives pour déterminer si des changements significatifs sont observés par rapport aux graphiques présentés dans la section \"Recherche de relations entre les variables explicatives et la variable d’intérêt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [:type, :nombre_cylindres, :cylindree, :transmission, :boite, :volume_gaz]\n",
    "\n",
    "plots = [\n",
    "    Gadfly.plot(\n",
    "        uniqueTrainDataExploration,\n",
    "        x=var,\n",
    "        y=:consommation,\n",
    "        Geom.point,\n",
    "        Guide.xlabel(string(var)),\n",
    "        Guide.ylabel(\"consommation\")\n",
    "    ) for var in variables\n",
    "]\n",
    "\n",
    "set_default_plot_size(35cm, 35cm)\n",
    "p = reshape(plots, (3,2))\n",
    "gridstack(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les graphiques ci-dessus présentent une allure similaire à ceux de la section \"Recherche de relations entre les variables explicatives et la variable d’intérêt\". Cela dit, il pourrait être intéressant de tester avec les modèles en ne conservant que les données uniques. Cette approche permet de simplifier le dataset en réduisant la redondance des observations ayant les mêmes caractéristiques explicatives. Cela pourrait faciliter l’apprentissage du modèle tout en améliorant son efficacité et en limitant les risques de confusion liés à des consommations différentes pour des données identiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des données aberrantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'analyse des données aberrantes, nous avons commencé par essayer des méthodes classiques avec les quantiles et le score-z. Les résultats étant trop différents d'un type à l'autre, nous avons plutôt opté pour une régression linéaire avec un seuil choisi. Ce choix de régression linéaire a été fait car le graphique de la cylindree en fonction de la consommation suit une tendance linéaire."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commence par trouver les indices (lignes) des données aberrantes avec la méthode get_outliers_ind_regression_lin :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_outliers_ind_regression_lin(data, x_col, y_col; threshold=2.5)\n",
    "    slope, intercept = linear_regression(data, x_col, y_col)\n",
    "    \n",
    "    x = data[!, x_col]\n",
    "    y = data[!, y_col]\n",
    "    \n",
    "    y_pred = slope .* x .+ intercept\n",
    "    \n",
    "    residuals = abs.(y .- y_pred)\n",
    "    \n",
    "    residuals_std = std(residuals)\n",
    "    \n",
    "    outlier_indices = findall(residuals .> threshold * residuals_std)\n",
    "    \n",
    "    outliers = data[outlier_indices, :]\n",
    "    \n",
    "    return outlier_indices\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, une méthode pour obtenir ces données aberrantes seulement (get_outliers_regression_lin) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_outliers_regression_lin(data, outliers_indices)\n",
    "    outliers = data[outliers_indices, :]\n",
    "    return outliers\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, une méthode pour les séparer des données régulières (remove_outliers_regression_lin):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function remove_outliers_regression_lin(data::DataFrame, x_col::Symbol, y_col::Symbol; threshold=2.5)\n",
    "    outlier_indices = get_outliers_ind_regression_lin(data, x_col, y_col, threshold=threshold)\n",
    "\n",
    "    # println(\"Outlier Indices Identified: \", outlier_indices)\n",
    "\n",
    "    keep_mask = trues(nrow(data))\n",
    "    \n",
    "    if !isempty(outlier_indices)\n",
    "        keep_mask[outlier_indices] .= false\n",
    "    end\n",
    "\n",
    "    cleaned_data = data[keep_mask, :]\n",
    "    \n",
    "    return cleaned_data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function linear_regression(data, x_col, y_col)\n",
    "    # Extract x and y data from the DataFrame\n",
    "    x = data[!, x_col]\n",
    "    y = data[!, y_col]\n",
    "    \n",
    "    # Ensure there is enough data for the calculation\n",
    "    n = length(x)\n",
    "    if n == 0\n",
    "        error(\"Cannot compute linear regression with zero elements.\")\n",
    "    end\n",
    "    \n",
    "    # Calculate the mean values\n",
    "    x_mean = mean(x)\n",
    "    y_mean = mean(y)\n",
    "    \n",
    "    # Calculate slope and intercept for linear regression\n",
    "    slope = sum((x .- x_mean) .* (y .- y_mean)) / sum((x .- x_mean).^2)\n",
    "    intercept = y_mean - slope * x_mean\n",
    "    \n",
    "    return slope, intercept\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dernièrement, une méthode pour visualiser les données avant et après le retrait des données aberrantes (plot_outliers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function plot_outliers(uniqueD)\n",
    "    # Step 2: Find and Display Outliers with Regression\n",
    "    outliers_indices = get_outliers_ind_regression_lin(uniqueD, :cylindree, :consommation)\n",
    "    outliers_regression = get_outliers_regression_lin(uniqueD, outliers_indices)\n",
    "   \n",
    "    # Step 3: Plot Original Data, Regression Line, and Outliers\n",
    "    slope, intercept = linear_regression(uniqueD, :cylindree, :consommation)\n",
    "    regression_line_y = slope .* uniqueD.cylindree .+ intercept\n",
    "   \n",
    "    layer_original = layer(x=uniqueD.cylindree, y=uniqueD.consommation, color=uniqueD.type, Theme(default_color=\"blue\"))\n",
    "    layer_linear_regression = layer(x=uniqueD.cylindree, y=regression_line_y, Geom.line, Theme(default_color=\"green\"))\n",
    "    layer_regression_outliers = layer(x=outliers_regression.cylindree, y=outliers_regression.consommation, Geom.point, Theme(default_color=\"red\"))\n",
    "    set_default_plot_size(15cm, 15cm)\n",
    "    \n",
    "    display(plot(layer_regression_outliers, layer_original, layer_linear_regression, Guide.xlabel(\"Cylindree\"), Guide.ylabel(\"Consommation\"), Guide.title(\"Original Data with Outliers\")))\n",
    "   \n",
    "    # Step 4: Remove Outliers Based on Regression Line\n",
    "    cleaned_data = remove_outliers_regression_lin(uniqueD, :cylindree, :consommation, threshold=2.5)\n",
    "   \n",
    "    # Step 5: Plot Cleaned Data with New Regression Line\n",
    "    slope_cleaned, intercept_cleaned = linear_regression(cleaned_data, :cylindree, :consommation)\n",
    "    regression_line_y_cleaned = slope_cleaned .* cleaned_data.cylindree .+ intercept_cleaned\n",
    "   \n",
    "   layer_cleaned = layer(x=cleaned_data.cylindree, y=cleaned_data.consommation, color=cleaned_data.type, Theme(default_color=\"blue\"))\n",
    "   layer_linear_regression_cleaned = layer(x=cleaned_data.cylindree, y=regression_line_y_cleaned, Geom.line, Theme(default_color=\"green\"))\n",
    "   \n",
    "   # Display plot for cleaned data\n",
    "   display(plot(layer_cleaned, layer_linear_regression_cleaned, \n",
    "                Guide.xlabel(\"Cylindree\"), Guide.ylabel(\"Consommation\"), Guide.title(\"Cleaned Data with Regression Line\")))\n",
    "   \n",
    "   end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_outliers(uniqueTrainDataExploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suite à l'exploration des données, nous allons construire un DataFrame avec toutes les variables explicatives que nous avons évaluer comme étant pertinente pour la prédiction de la consommation...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons standardisé les données numériques pour mettre toutes nos données sur la même échelle. De cette façon, on peut comparer leur importance relative. De plus, une variable ayant des valeurs très hautes comparées aux autres n'influencera pas les données de façon plus significative qu'elle le devrait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMSOMMATION_MEAN = mean(trainData.consommation)\n",
    "COMSOMMATION_STD = std(trainData.consommation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function standardize(data)\n",
    "    return (data .- mean(data)) ./ std(data)\n",
    "end\n",
    "\n",
    "function standardize_data(data)\n",
    "    stddata = deepcopy(data)\n",
    "   for col in names(stddata)\n",
    "        if eltype(stddata[!, col]) <: Number && col != \"id\"\n",
    "            stddata[!, col] = standardize(stddata[!, col])\n",
    "        end\n",
    "    end\n",
    "    return stddata\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function add_rows(data)\n",
    "    data[!,:volume_gaz] = data[!,:nombre_cylindres] .* data[!,:cylindree]\n",
    "\n",
    "    #https://www.insurancenavy.com/average-car-weight/\n",
    "    #https://www.auto-tests.com/fr/lightest-weight/Wagon/all/\n",
    "    weight_dict = Dict(\"voiture_moyenne\" => 3300, \"VUS_petit\" => 3500, \"voiture_compacte\" => 2800, \"voiture_deux_places\" => 2800, \"voiture_minicompacte\" => 1500, \"VUS_standard\" => 5000, \"monospace\" => 4500, \"voiture_sous_compacte\" => 2600, \"camionnette_petit\" => 4200, \"break_petit\" => 2640, \"voiture_grande\" => 4400, \"camionnette_standard\" => 4700, \"break_moyen\" => 3300)\n",
    "    data[!, :weight] = [weight_dict[t] for t in data[!, :type]]\n",
    "\n",
    "    general_type_dict = Dict(\"voiture_moyenne\" => \"voiture\", \"VUS_petit\" => \"VUS\", \"voiture_compacte\" => \"voiture\", \"voiture_deux_places\" => \"voiture\", \"voiture_minicompacte\" => \"voiture\", \"VUS_standard\" => \"VUS\", \"monospace\" => \"camionnette\", \"voiture_sous_compacte\" => \"voiture\", \"camionnette_petit\" => \"camionnette\", \"break_petit\" => \"break\", \"voiture_grande\" => \"voiture\", \"camionnette_standard\" => \"camionnette\", \"break_moyen\" => \"break\")\n",
    "    data[!, :general_type] = [general_type_dict[t] for t in data[!, :type]]\n",
    "    \n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getStandardEncodedData(data)\n",
    "    data_copy = deepcopy(data)\n",
    "    standardised_data = get_unique_data(data_copy)\n",
    "    standardised_data = add_rows(data_copy)\n",
    "    standardised_data = standardize_data(data_copy)\n",
    "    standardised_data = encode_data(standardised_data)\n",
    "    standardised_data = removeRows(standardised_data)\n",
    "    \n",
    "    return standardised_data\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calcul rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons évalué nos modèles avec la métrique rmse, car c'est celle-ci qui est utilisée pour évaluer nos prédictions dans le concours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function rmse(y, prediction)\n",
    "    return sqrt(mean((prediction .- y).^2))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons calculé le rmse moyen en faisant une séparation aléatoire des données à chaque fois afin d'avoir une idée générale du rmse de chaque modèle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluate_rmse(data, model, nrange = 1000, test_size = 0.2, param = 0.0, should_print = true)\n",
    "    n = 0\n",
    "    for i in range(0, 1, length=nrange)\n",
    "        train_data, test_data = train_test_split(data, test_size)\n",
    "        if (param == 0.0)\n",
    "            n += model(train_data, test_data)[1]\n",
    "        else\n",
    "        n += model(train_data, test_data, param)[1]\n",
    "        end\n",
    "    end\n",
    "    average_rmse = n/nrange\n",
    "    if should_print\n",
    "        print(\"average rmse: \", average_rmse, \"\\n\")\n",
    "    end\n",
    "    return average_rmse\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation des ensemble d'entrainement et de validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons effectué les tests sur nos modèles en prenant soin de séparé les données en ensemble d'entraînement et en ensemble de test. Par défaut, nos données sont séparées 80% dans l'ensemble d'entraînement et 20% dans l'ensemble de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_test_split(data, test_size=0.2, shuffle=true)\n",
    "    n = size(data, 1)\n",
    "    test_size = floor(Int, n * test_size)\n",
    "    \n",
    "    if shuffle\n",
    "        indices = randperm(n)\n",
    "    else\n",
    "        indices = 1:n\n",
    "    end\n",
    "    \n",
    "    test_indices = indices[1:test_size]\n",
    "    train_indices = indices[test_size+1:end]\n",
    "    \n",
    "    train_data = data[train_indices, :]\n",
    "    test_data = data[test_indices, :]\n",
    "    \n",
    "    return train_data, test_data\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une liste des toutes les modèles prédictifs que nous avons implémenter et tester afin d'obtenir les meilleures prédictions de consommation d'essence:\n",
    "- Régression linéaire\n",
    "- Régression ridge\n",
    "- Régression SVD\n",
    "- Régression polynomiale\n",
    "- Arbres de classification\n",
    "- Forêt de classification\n",
    "\n",
    "Voici leurs implémentations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le premier modèle que nous avons implémenté est la régression linéaire. Ce modèle nous semblait intuitif, car les données explicatives cylindree, nombre_cylindre et volume_gaz semblent suivre une relation linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function regression(training_data, test_data = nothing)\t\n",
    "    X_train =  Matrix(training_data[:, Not(:consommation, :id)])\n",
    "    y_train = training_data[:, :consommation]\n",
    "\n",
    "    beta = X_train \\ y_train\n",
    "\n",
    "    rmseval = 0.0\n",
    "    if test_data != nothing\n",
    "        X_test = Matrix(test_data[:, Not(:consommation, :id)])\n",
    "        y_test = test_data[:, :consommation]\n",
    "        y_predict =  X_test * beta\n",
    "        y_predict = (y_predict .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        y_test = (y_test .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        rmseval = rmse(y_test, y_predict)\n",
    "    end\n",
    "    \n",
    "    return rmseval, beta\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_rmse(getStandardEncodedData(trainData), regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que le rmse moyen obtenu est relativement bas. Le modèle a donc du potentiel et pourrait peut-être être amélioré. Cependant, lorsque nous avons fait une remise officielle sur Kaggle, notre résultat a été nettement supérieur. On peut donc penser que le modèle ne prend pas en compte les données extrêmes et les tendances différentes avec des combinaisons de données spécifiques. On peut donc conclure que la régression linéaire n'est pas la meilleure méthode pour prédire la consommation d'essence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le deuxième modèle que nous avons implémenté est la régression ridge. Ce modèle permet de réduire l'importance de la colinéarité entre les données et ainsi réduire la variance du modèle. Cependant, cela introduit un biais dans le modèle. En atteignant un équilibre entre le biais introduit et la diminution de la variance, il est possible de minimiser le rmse. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function ridge_regression(training_data, test_data = nothing, lambda=0.5)\n",
    "    X_train = Matrix(training_data[:, Not([:consommation, :id])])\n",
    "    y_train = training_data[:, :consommation]\n",
    "    beta = (X_train'X_train + lambda*I)\\X_train'y_train\n",
    "\n",
    "    rmseval = 0.0\n",
    "    if test_data != nothing\n",
    "        X_test = Matrix(test_data[:, Not(:consommation, :id)])\n",
    "        y_test = test_data[:, :consommation]\n",
    "        ychap =  X_test * beta\n",
    "        ychap = (ychap .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        y_test = (y_test .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        rmseval = rmse(y_test, ychap)\n",
    "    end\n",
    "    return rmseval, beta\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On effectue le calcul du rmse avec plusieurs lambda différent afin de trouver le meilleur lambda possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse_data = DataFrame(lambda=Float64[], rmse=Float64[])\n",
    "for i in 0.1:0.1:40.0\n",
    "    rmseval = evaluate_rmse(getStandardEncodedData(trainData), ridge_regression, 1000, 0.2, i, false)\n",
    "    push!(rmse_data, (i, rmseval))\n",
    "end\n",
    "display(plot(rmse_data, x=:lambda, y=:rmse, Geom.line, Guide.xlabel(\"Lambda\"), Guide.ylabel(\"RMSE\")))\n",
    "\n",
    "filtered_rmse_data = filter(row -> row[:lambda] < 10, rmse_data)\n",
    "display(plot(filtered_rmse_data, x=:lambda, y=:rmse, Geom.line, Guide.xlabel(\"Lambda\"), Guide.ylabel(\"RMSE\")))\n",
    "\n",
    "best_row = rmse_data[argmin(rmse_data.rmse),:]\n",
    "println(\"meilleur lambda: \", best_row.lambda)\n",
    "println(\"rmse correspondant: \", best_row.rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir qu'il y a beaucoup de variation dans la valeur de rmse dépendamment de la valeur de lambda. Cette variation est causé en partie par la manière aléatoire avec laquelle les données sont séparées en ensemble d'entraînement et de test. On voit toutefois une tendance à la hausse lorsque lambda dépasse 10. On a donc fait un deuxième graphique pour mieux voir les données entre 0.1 et 10. On a ensuite trouvé la valeur de lambda qui donne le meilleur rmse. Ce rmse est comparable à celui de la régression linéaire. La régression ridge souffre des mêmes problèmes que la régression linéaire. On peut donc conclure que la régression ridge n'est pas la meilleure méthode pour prédire la consommation d'essence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le troisième modèle que nous avons implémenté est la régression SVD. Ce modèle permet de décerner s'il pourrait y avoir des variables et des relations entre les variables latentes qui peuvent améliorer nos prédictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function svd_regression(training_data, test_data = nothing)\n",
    "    X_train = Matrix(training_data[:, Not([:consommation, :id])])\n",
    "    y_train = training_data[:, :consommation]\n",
    "    \n",
    "    U, S, V = svd(X_train)\n",
    "\n",
    "    beta = V' * Diagonal([s > 1e-10 ? 1/s : 0 for s in S]) * U' * y_train\n",
    "\n",
    "    rmseval = 0.0\n",
    "    if test_data != nothing\n",
    "        X_test = Matrix(test_data[:, Not(:consommation,:id)])\n",
    "        y_test = test_data[:, :consommation]\n",
    "        ychap =  X_test * beta\n",
    "        ychap = (ychap .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        y_test = (y_test .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        rmseval = rmse(y_test, ychap)\n",
    "    end\n",
    "    return rmseval, beta\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_rmse(getStandardEncodedData(trainData), svd_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le modèle de régression SVD obtient un rmse très élevé. Avec les données que nous avons, il semble que le modèle de régression SVD surcomplexifie le modèle et donc nuit aux résulats. On peut donc conclure que la régression SVD n'est pas la meilleure méthode pour prédire la consommation d'essence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### régression polynomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le quatrième modèle que nous avons implémenté est la régression polynomiale. Ce modèle permet de modéliser des relations non-linéaires. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function construct_structure(x::Matrix{<:Real}, order::Int)\n",
    "    n, m = size(x)\n",
    "    poly_terms = [x[:, j].^p for j in 1:m, p in 0:order]\n",
    "    X = hcat(poly_terms...)\n",
    "    return X\n",
    "end\n",
    "\n",
    "function polynomial_regression(training_data, test_data = nothing, degree = 3)\n",
    "    X_train = construct_structure(Matrix(training_data[:, Not([:consommation, :id])]), degree)\n",
    "    y_train = training_data[:, :consommation]\n",
    "\n",
    "    beta = X_train \\ y_train\n",
    "\n",
    "    rmseval = 0.0\n",
    "\n",
    "    if test_data != nothing\n",
    "        X_test = construct_structure(Matrix(test_data[:, Not([:consommation, :id])]), degree)\n",
    "        y_test = test_data[:, :consommation]\n",
    "        ychap = X_test * beta\n",
    "        ychap = (ychap .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        y_test = (y_test .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "\n",
    "        rmseval = rmse(y_test, ychap)\n",
    "    end\n",
    "\n",
    "    return rmseval, beta\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_rmse(getStandardEncodedData(trainData), polynomial_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut voir que le rmse moyen obtenu est relativement bas. Le modèle a donc du potentiel et pourrait peut-être être amélioré. Cependant, lorsque nous avons fait une remise officielle sur Kaggle, notre résultat a été nettement supérieur. On peut donc penser que le modèle ne prend pas en compte les données extrêmes et les tendances différentes avec des combinaisons de données spécifiques. On peut donc conclure que la régression polynomiale n'est pas la meilleure méthode pour prédire la consommation d'essence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arbre de régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le cinquième modèle que nous avons implémenté est un arbre de régression. Ce modèle permet d'effectuer des séparations dans l'ensemble d'entraînement afin de discerner des liens entre certaines variables et d'ainsi mieux prédire les cas extrêmes et les combinaisons de données spécifiques. Ce modèle tente donc de pallier aux problèmes des modèles linéaire, ridge et polynomiale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "DecisionTreeRegressor(; pruning_purity_threshold=0.0,\n",
       "                      max_depth::Int-1,\n",
       "                      min_samples_leaf::Int=5,\n",
       "                      min_samples_split::Int=2,\n",
       "                      min_purity_increase::Float=0.0,\n",
       "                      n_subfeatures::Int=0,\n",
       "                      rng=Random.GLOBAL_RNG,\n",
       "                      impurity_importance::Bool=true)\n",
       "\\end{verbatim}\n",
       "Decision tree regression. See \\href{https://github.com/bensadeghi/DecisionTree.jl}{DecisionTree.jl's documentation}\n",
       "\n",
       "Hyperparameters:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{pruning\\_purity\\_threshold}: (post-pruning) merge leaves having \\texttt{>=thresh} combined purity (default: no pruning). This accuracy-based method may not be appropriate for regression tree.\n",
       "\n",
       "\n",
       "\\item \\texttt{max\\_depth}: maximum depth of the decision tree (default: no maximum)\n",
       "\n",
       "\n",
       "\\item \\texttt{min\\_samples\\_leaf}: the minimum number of samples each leaf needs to have (default: 5)\n",
       "\n",
       "\n",
       "\\item \\texttt{min\\_samples\\_split}: the minimum number of samples in needed for a split (default: 2)\n",
       "\n",
       "\n",
       "\\item \\texttt{min\\_purity\\_increase}: minimum purity needed for a split (default: 0.0)\n",
       "\n",
       "\n",
       "\\item \\texttt{n\\_subfeatures}: number of features to select at random (default: keep all)\n",
       "\n",
       "\n",
       "\\item \\texttt{rng}: the random number generator to use. Can be an \\texttt{Int}, which will be used to seed and create a new random number generator.\n",
       "\n",
       "\n",
       "\\item \\texttt{impurity\\_importance}: whether to calculate feature importances using \\texttt{Mean Decrease in Impurity (MDI)}. See \\href{@ref}{\\texttt{DecisionTree.impurity\\_importance}}\n",
       "\n",
       "\\end{itemize}\n",
       "Implements \\texttt{fit!}, \\texttt{predict}, \\texttt{get\\_classes}\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "DecisionTreeRegressor(; pruning_purity_threshold=0.0,\n",
       "                      max_depth::Int-1,\n",
       "                      min_samples_leaf::Int=5,\n",
       "                      min_samples_split::Int=2,\n",
       "                      min_purity_increase::Float=0.0,\n",
       "                      n_subfeatures::Int=0,\n",
       "                      rng=Random.GLOBAL_RNG,\n",
       "                      impurity_importance::Bool=true)\n",
       "```\n",
       "\n",
       "Decision tree regression. See [DecisionTree.jl's documentation](https://github.com/bensadeghi/DecisionTree.jl)\n",
       "\n",
       "Hyperparameters:\n",
       "\n",
       "  * `pruning_purity_threshold`: (post-pruning) merge leaves having `>=thresh` combined purity (default: no pruning). This accuracy-based method may not be appropriate for regression tree.\n",
       "  * `max_depth`: maximum depth of the decision tree (default: no maximum)\n",
       "  * `min_samples_leaf`: the minimum number of samples each leaf needs to have (default: 5)\n",
       "  * `min_samples_split`: the minimum number of samples in needed for a split (default: 2)\n",
       "  * `min_purity_increase`: minimum purity needed for a split (default: 0.0)\n",
       "  * `n_subfeatures`: number of features to select at random (default: keep all)\n",
       "  * `rng`: the random number generator to use. Can be an `Int`, which will be used to seed and create a new random number generator.\n",
       "  * `impurity_importance`: whether to calculate feature importances using `Mean Decrease in Impurity (MDI)`. See [`DecisionTree.impurity_importance`](@ref)\n",
       "\n",
       "Implements `fit!`, `predict`, `get_classes`\n"
      ],
      "text/plain": [
       "\u001b[36m  DecisionTreeRegressor(; pruning_purity_threshold=0.0,\u001b[39m\n",
       "\u001b[36m                        max_depth::Int-1,\u001b[39m\n",
       "\u001b[36m                        min_samples_leaf::Int=5,\u001b[39m\n",
       "\u001b[36m                        min_samples_split::Int=2,\u001b[39m\n",
       "\u001b[36m                        min_purity_increase::Float=0.0,\u001b[39m\n",
       "\u001b[36m                        n_subfeatures::Int=0,\u001b[39m\n",
       "\u001b[36m                        rng=Random.GLOBAL_RNG,\u001b[39m\n",
       "\u001b[36m                        impurity_importance::Bool=true)\u001b[39m\n",
       "\n",
       "  Decision tree regression. See DecisionTree.jl's documentation\n",
       "  (https://github.com/bensadeghi/DecisionTree.jl)\n",
       "\n",
       "  Hyperparameters:\n",
       "\n",
       "    •  \u001b[36mpruning_purity_threshold\u001b[39m: (post-pruning) merge leaves having\n",
       "       \u001b[36m>=thresh\u001b[39m combined purity (default: no pruning). This\n",
       "       accuracy-based method may not be appropriate for regression tree.\n",
       "\n",
       "    •  \u001b[36mmax_depth\u001b[39m: maximum depth of the decision tree (default: no\n",
       "       maximum)\n",
       "\n",
       "    •  \u001b[36mmin_samples_leaf\u001b[39m: the minimum number of samples each leaf needs to\n",
       "       have (default: 5)\n",
       "\n",
       "    •  \u001b[36mmin_samples_split\u001b[39m: the minimum number of samples in needed for a\n",
       "       split (default: 2)\n",
       "\n",
       "    •  \u001b[36mmin_purity_increase\u001b[39m: minimum purity needed for a split (default:\n",
       "       0.0)\n",
       "\n",
       "    •  \u001b[36mn_subfeatures\u001b[39m: number of features to select at random (default:\n",
       "       keep all)\n",
       "\n",
       "    •  \u001b[36mrng\u001b[39m: the random number generator to use. Can be an \u001b[36mInt\u001b[39m, which will\n",
       "       be used to seed and create a new random number generator.\n",
       "\n",
       "    •  \u001b[36mimpurity_importance\u001b[39m: whether to calculate feature importances\n",
       "       using \u001b[36mMean Decrease in Impurity (MDI)\u001b[39m. See\n",
       "       \u001b[36mDecisionTree.impurity_importance\u001b[39m\n",
       "\n",
       "  Implements \u001b[36mfit!\u001b[39m, \u001b[36mpredict\u001b[39m, \u001b[36mget_classes\u001b[39m"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tree_regression (generic function with 2 methods)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function tree_regression(training_data, test_data = nothing)\n",
    "    X_train = Matrix(training_data[:, Not(:consommation, :id)])\n",
    "    y_train = training_data.consommation\n",
    "    X_test = Matrix(test_data[:, Not(:consommation,:id)])\n",
    "    y_test = test_data.consommation\n",
    "\n",
    "    model = DecisionTreeRegressor(n_subfeatures=12,min_samples_leaf=1,min_purity_increase=0.0, max_depth=5, min_samples_split=6)\n",
    "    fit!(model, X_train, y_train)\n",
    "    ychap =  predict(model, X_test)  \n",
    "\n",
    "    ychap = (ychap .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "    y_test = (y_test .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "    rmseval = rmse(y_test, ychap)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average rmse: 0.9434730569908875\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9434730569908875"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rmse(getStandardEncodedData(trainData), tree_regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le résultat est similaire à ceux des modèles linéaire, ridge et polynomiale. Cela peut être expliqué par le fait qu'un arbre de régression comporte généralement une assez grande variance. De plus, si certaines données n'ont pas de données similaires dans l'ensemble d'entraînement, celles-ci peuvent être très difficiles à prédire. Ce modèle pourrait donc être amélioré."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Forêt aléatoire de régression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le sixième modèle que nous avons implémenté est une forêt aléatoire de régression. Ce modèle utilise plusieurs arbre de régression afin de pallier aux problèmes engendrés par le fait d'utiliser un seul arbre de régression. Ce modèle devrait donc amélioré les résultats du modèle précédent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "RandomForestRegressor(; n_subfeatures::Int=-1,\n",
       "                      n_trees::Int=10,\n",
       "                      partial_sampling::Float=0.7,\n",
       "                      max_depth::Int=-1,\n",
       "                      min_samples_leaf::Int=5,\n",
       "                      rng=Random.GLOBAL_RNG,\n",
       "                      impurity_importance::Bool=true)\n",
       "\\end{verbatim}\n",
       "Random forest regression. See \\href{https://github.com/bensadeghi/DecisionTree.jl}{DecisionTree.jl's documentation}\n",
       "\n",
       "Hyperparameters:\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{n\\_subfeatures}: number of features to consider at random per split (default: -1, sqrt(\\# features))\n",
       "\n",
       "\n",
       "\\item \\texttt{n\\_trees}: number of trees to train (default: 10)\n",
       "\n",
       "\n",
       "\\item \\texttt{partial\\_sampling}: fraction of samples to train each tree on (default: 0.7)\n",
       "\n",
       "\n",
       "\\item \\texttt{max\\_depth}: maximum depth of the decision trees (default: no maximum)\n",
       "\n",
       "\n",
       "\\item \\texttt{min\\_samples\\_leaf}: the minimum number of samples each leaf needs to have (default: 5)\n",
       "\n",
       "\n",
       "\\item \\texttt{min\\_samples\\_split}: the minimum number of samples in needed for a split\n",
       "\n",
       "\n",
       "\\item \\texttt{min\\_purity\\_increase}: minimum purity needed for a split\n",
       "\n",
       "\n",
       "\\item \\texttt{rng}: the random number generator to use. Can be an \\texttt{Int}, which will be used to seed and create a new random number generator. Multi-threaded forests must be seeded with an \\texttt{Int}\n",
       "\n",
       "\n",
       "\\item \\texttt{impurity\\_importance}: whether to calculate feature importances using \\texttt{Mean Decrease in Impurity (MDI)}. See \\href{@ref}{\\texttt{DecisionTree.impurity\\_importance}}.\n",
       "\n",
       "\\end{itemize}\n",
       "Implements \\texttt{fit!}, \\texttt{predict}, \\texttt{get\\_classes}\n",
       "\n"
      ],
      "text/markdown": [
       "```\n",
       "RandomForestRegressor(; n_subfeatures::Int=-1,\n",
       "                      n_trees::Int=10,\n",
       "                      partial_sampling::Float=0.7,\n",
       "                      max_depth::Int=-1,\n",
       "                      min_samples_leaf::Int=5,\n",
       "                      rng=Random.GLOBAL_RNG,\n",
       "                      impurity_importance::Bool=true)\n",
       "```\n",
       "\n",
       "Random forest regression. See [DecisionTree.jl's documentation](https://github.com/bensadeghi/DecisionTree.jl)\n",
       "\n",
       "Hyperparameters:\n",
       "\n",
       "  * `n_subfeatures`: number of features to consider at random per split (default: -1, sqrt(# features))\n",
       "  * `n_trees`: number of trees to train (default: 10)\n",
       "  * `partial_sampling`: fraction of samples to train each tree on (default: 0.7)\n",
       "  * `max_depth`: maximum depth of the decision trees (default: no maximum)\n",
       "  * `min_samples_leaf`: the minimum number of samples each leaf needs to have (default: 5)\n",
       "  * `min_samples_split`: the minimum number of samples in needed for a split\n",
       "  * `min_purity_increase`: minimum purity needed for a split\n",
       "  * `rng`: the random number generator to use. Can be an `Int`, which will be used to seed and create a new random number generator. Multi-threaded forests must be seeded with an `Int`\n",
       "  * `impurity_importance`: whether to calculate feature importances using `Mean Decrease in Impurity (MDI)`. See [`DecisionTree.impurity_importance`](@ref).\n",
       "\n",
       "Implements `fit!`, `predict`, `get_classes`\n"
      ],
      "text/plain": [
       "\u001b[36m  RandomForestRegressor(; n_subfeatures::Int=-1,\u001b[39m\n",
       "\u001b[36m                        n_trees::Int=10,\u001b[39m\n",
       "\u001b[36m                        partial_sampling::Float=0.7,\u001b[39m\n",
       "\u001b[36m                        max_depth::Int=-1,\u001b[39m\n",
       "\u001b[36m                        min_samples_leaf::Int=5,\u001b[39m\n",
       "\u001b[36m                        rng=Random.GLOBAL_RNG,\u001b[39m\n",
       "\u001b[36m                        impurity_importance::Bool=true)\u001b[39m\n",
       "\n",
       "  Random forest regression. See DecisionTree.jl's documentation\n",
       "  (https://github.com/bensadeghi/DecisionTree.jl)\n",
       "\n",
       "  Hyperparameters:\n",
       "\n",
       "    •  \u001b[36mn_subfeatures\u001b[39m: number of features to consider at random per split\n",
       "       (default: -1, sqrt(# features))\n",
       "\n",
       "    •  \u001b[36mn_trees\u001b[39m: number of trees to train (default: 10)\n",
       "\n",
       "    •  \u001b[36mpartial_sampling\u001b[39m: fraction of samples to train each tree on\n",
       "       (default: 0.7)\n",
       "\n",
       "    •  \u001b[36mmax_depth\u001b[39m: maximum depth of the decision trees (default: no\n",
       "       maximum)\n",
       "\n",
       "    •  \u001b[36mmin_samples_leaf\u001b[39m: the minimum number of samples each leaf needs to\n",
       "       have (default: 5)\n",
       "\n",
       "    •  \u001b[36mmin_samples_split\u001b[39m: the minimum number of samples in needed for a\n",
       "       split\n",
       "\n",
       "    •  \u001b[36mmin_purity_increase\u001b[39m: minimum purity needed for a split\n",
       "\n",
       "    •  \u001b[36mrng\u001b[39m: the random number generator to use. Can be an \u001b[36mInt\u001b[39m, which will\n",
       "       be used to seed and create a new random number generator.\n",
       "       Multi-threaded forests must be seeded with an \u001b[36mInt\u001b[39m\n",
       "\n",
       "    •  \u001b[36mimpurity_importance\u001b[39m: whether to calculate feature importances\n",
       "       using \u001b[36mMean Decrease in Impurity (MDI)\u001b[39m. See\n",
       "       \u001b[36mDecisionTree.impurity_importance\u001b[39m.\n",
       "\n",
       "  Implements \u001b[36mfit!\u001b[39m, \u001b[36mpredict\u001b[39m, \u001b[36mget_classes\u001b[39m"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@doc RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "random_forest (generic function with 2 methods)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function random_forest(training_data, test_data = nothing)\n",
    "    X_train =  Matrix(training_data[:, Not(:consommation, :id)])\n",
    "    y_train = training_data.consommation\n",
    "    X_test = Matrix(test_data[:, Not(:consommation, :id)])\n",
    "    y_test = test_data.consommation\n",
    "\n",
    "\n",
    "    model = RandomForestRegressor(n_subfeatures=12, n_trees=1000,min_samples_leaf=1,min_purity_increase=0.0, max_depth=5, min_samples_split=6)\n",
    "    DecisionTree.fit!(model, X_train, y_train)\n",
    "    ychap = DecisionTree.predict(model, X_test)\n",
    "    y_test = (y_test * COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "    ychap = (ychap * COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "    return rmse(y_test, ychap)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average rmse: 0.8699680936094508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8699680936094508"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rmse(getStandardEncodedData(trainData), random_forest, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit donc que le rmse moyen obtenu est inférieur à celui de tous les modèles précédents. Ce modèle a donc du potentiel et pourrait être amélioré.Cependant, lorsque nous avons fait une remise officielle sur Kaggle, notre résultat a été nettement supérieur. Il y a donc potentiellement des combinaisons de données qui ne se retrouve pas dans les données d'entraînement. C'est une des faiblesse du modèle de forêt aléatoire de régression. On peut donc conclure que la forêt aléatoire de régression n'est pas la meilleure méthode pour prédire la consommation d'essence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparaison des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous les modèles, à l'exception de la régression SVD qui est nettement pire, ont un rmse moyen relativement semblable et comportent tous des défauts. Bien que l'écart soit petit, le modèle forêt aléatoire de régression a obtenu le meilleur résultat. \n",
    "\n",
    "Chacun de ces modèles n'a pas performé à la hauteur des résulats attendus lors de nos remises sur Kaggle. Il faut donc apporter des modifications afin de les rendre meilleurs pour prédire des données qui ne sont pas dans l'ensemble d'entraînement.\n",
    "\n",
    "Nous avons décider d'implémenter un modèle basé sur les arbres de régression afin de faire notre remise finale. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion et amélioration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
