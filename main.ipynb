{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concours MTH3302\n",
    "#### Polytechnique Montréal\n",
    "### Projet A2024\n",
    "----\n",
    "### Objectif\n",
    "Prédire **la `consommation` en carburant de voitures récentes**.\n",
    "\n",
    "### Données\n",
    "Le jeu de données contient pour presque 400 véhicule, la consommation moyenne en L/100km, l'année de frabrication, le type de véhicule, le nombre de cylindre, cylindree, la transmission et la boite.\n",
    "\n",
    "- `train.csv` est l'ensemble d'entraînement\n",
    "- `test.csv` est l'ensemble de test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des librairies utilisées dans le calepin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, Combinatorics, Random, LinearAlgebra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premier fichier est l'ensemble des données pour l'entrainement, il contient l'année, le type, le nombre_cylindres, la cylindree, la transmission, la boite, la consommation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div style = \"float: left;\"><span>1×8 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">annee</th><th style = \"text-align: left;\">type</th><th style = \"text-align: left;\">nombre_cylindres</th><th style = \"text-align: left;\">cylindree</th><th style = \"text-align: left;\">transmission</th><th style = \"text-align: left;\">boite</th><th style = \"text-align: left;\">consommation</th><th style = \"text-align: left;\">id</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"String31\" style = \"text-align: left;\">String31</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String15\" style = \"text-align: left;\">String15</th><th title = \"String15\" style = \"text-align: left;\">String15</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">2023</td><td style = \"text-align: left;\">voiture_moyenne</td><td style = \"text-align: right;\">8</td><td style = \"text-align: right;\">4.4</td><td style = \"text-align: left;\">integrale</td><td style = \"text-align: left;\">automatique</td><td style = \"text-align: right;\">13.8359</td><td style = \"text-align: right;\">1</td></tr></tbody></table></div>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccccc}\n",
       "\t& annee & type & nombre\\_cylindres & cylindree & transmission & boite & \\\\\n",
       "\t\\hline\n",
       "\t& Int64 & String31 & Int64 & Float64 & String15 & String15 & \\\\\n",
       "\t\\hline\n",
       "\t1 & 2023 & voiture\\_moyenne & 8 & 4.4 & integrale & automatique & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m1×8 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m annee \u001b[0m\u001b[1m type            \u001b[0m\u001b[1m nombre_cylindres \u001b[0m\u001b[1m cylindree \u001b[0m\u001b[1m transmission \u001b[0m\u001b[1m boit\u001b[0m ⋯\n",
       "     │\u001b[90m Int64 \u001b[0m\u001b[90m String31        \u001b[0m\u001b[90m Int64            \u001b[0m\u001b[90m Float64   \u001b[0m\u001b[90m String15     \u001b[0m\u001b[90m Stri\u001b[0m ⋯\n",
       "─────┼──────────────────────────────────────────────────────────────────────────\n",
       "   1 │  2023  voiture_moyenne                 8        4.4  integrale     auto ⋯\n",
       "\u001b[36m                                                               3 columns omitted\u001b[0m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData = CSV.read(\"./data/train.csv\", DataFrame)\n",
    "trainData.consommation = parse.(Float64,replace.(trainData.consommation, \",\" => \".\"))\n",
    "trainData.cylindree = parse.(Float64,replace.(trainData.cylindree, \",\" => \".\"))\n",
    "trainData[!, :id] = 1:nrow(trainData)\n",
    "first(trainData, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le deuxième fichier est l'ensemble des données pour le test, il contient l'année, le type, le nombre_cylindres, la cylindree, la transmission, la boite. Ici il n'a pas la consommation car il s'agit de la variable d'intérêt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = CSV.read(\"./data/test.csv\", DataFrame)\n",
    "first(testData, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lors de l’étape d’exploration des données, notre objectif principal était de mieux comprendre les caractéristiques disponibles afin d’évaluer leur pertinence pour la prédiction de la `consommation` en carburant. Nous avons adopté une approche intuitive, en nous appuyant sur nos connaissances de base concernant les véhicules et leur consommation, pour repérer les tendances et des relations potentielles entre les variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chargement donnée pour l'exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargeons les données pour l'exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataExploration = CSV.read(\"./data/train.csv\", DataFrame)\n",
    "testDataExploration = CSV.read(\"./data/test.csv\", DataFrame)\n",
    "first(trainDataExploration, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vérifions s'il y a des données manquantes dans l'ensemble d'entrainement et de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "missing_data (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function missing_data(data)\n",
    "    return  mapcols(x -> sum(ismissing.(x)), data)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data(trainDataExploration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data(testDataExploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons constater qu'il n'y a pas de données manquantes dans les données fournies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conversion des données : préparation des colonnes pour l'analyse et l'évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étant donné que les colonnes `cylindree` et `consommation` sont actuellement définies comme `String3` et `String31` respectivement, il est nécessaire de modifier leur type en `Float64` dans les deux ensembles de données afin de pouvoir les analyser correctement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataExploration.consommation = parse.(Float64,replace.(trainDataExploration.consommation, \",\" => \".\"))\n",
    "trainDataExploration.cylindree = parse.(Float64,replace.(trainDataExploration.cylindree, \",\" => \".\"))\n",
    "first(trainDataExploration, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de nouvelles variables explicatives : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour enrichir notre analyse et améliorer les performances du modèle, nous avons ajouté de nouvelles variables explicatives.  Il est a noter qu'il se peut qu'au final on ne les utilise pas. Nous ferons une synthèse des variables explicatives sélectionnées après l'exploration des données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `volume_gaz`\n",
    "Cette variable est calculée comme le produit du nombre de cylindres et de la cylindrée du moteur. Elle reflète la capacité totale de déplacement du moteur, ce qui pourrait avoir une influence directe sur la consommation de carburant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataExploration[!,:volume_gaz] = trainDataExploration[!,:nombre_cylindres] .* trainDataExploration[!,:cylindree]\n",
    "first(trainDataExploration, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `weight`\n",
    "Nous avons regarder le poids moyen par types de véhicules en se fiant aux liens suivants:\n",
    "https://www.insurancenavy.com/average-car-weight/\n",
    "https://www.auto-tests.com/fr/lightest-weight/Wagon/all/. L'ajout de cette variable a pour but d'établir un lien entre les différents types de véhicules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_dict = Dict(\n",
    "    \"voiture_moyenne\" => 3300, \n",
    "    \"VUS_petit\" => 3500, \n",
    "    \"voiture_compacte\" => 2800, \n",
    "    \"voiture_deux_places\" => 2800, \n",
    "    \"voiture_minicompacte\" => 1500, \n",
    "    \"VUS_standard\" => 5000, \n",
    "    \"monospace\" => 4500, \n",
    "    \"voiture_sous_compacte\" => 2600, \n",
    "    \"camionnette_petit\" => 4200, \n",
    "    \"break_petit\" => 2640, \n",
    "    \"voiture_grande\" => 4400, \n",
    "    \"camionnette_standard\" => 4700, \n",
    "    \"break_moyen\" => 3300)\n",
    "trainDataExploration[!, :weight] = [weight_dict[t] for t in trainDataExploration[!, :type]]\n",
    "first(trainDataExploration, 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recherche de relation entre les variables explicatives et la variable d'intérêt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysons maintenant chacune des variables de l'ensemble d'entraînement en fonction de notre variable cible, la `consommation`. Cette étape vise à détecter les relations potentielles entre les variables. Concrètement, nous traçons des graphiques de `consommation` en fonction de différentes variables, telles que : `annee`, `type`, `nombre_cylindres`, `cylindree`, `transmission`, `boite`, `volume_gaz` et `weight`. Nous faisons cela afin de détecter une tendance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [:annee, :type, :nombre_cylindres, :cylindree, :transmission, :boite, :volume_gaz, :weight]\n",
    "\n",
    "plots = [\n",
    "    Gadfly.plot(\n",
    "        trainDataExploration,\n",
    "        x=var,\n",
    "        y=:consommation,\n",
    "        Geom.point,\n",
    "        Guide.xlabel(string(var)),\n",
    "        Guide.ylabel(\"consommation\")\n",
    "    ) for var in variables\n",
    "]\n",
    "\n",
    "set_default_plot_size(35cm, 35cm)\n",
    "p = reshape(plots, (4,2))\n",
    "gridstack(p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valeurs_nombre_cylindres = unique(trainDataExploration[:,:nombre_cylindres])\n",
    "println(\"Valeurs distinctes de la colonne :nombre_cylindres : \", valeurs_nombre_cylindres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse des graphiques ci-dessus:\n",
    "\n",
    "Pour les variables explicatives suivantes en fonction de la consommation:\n",
    "- `annee` : La distribution de la consommation selon les années semble relativement homogène. On observe cependant une légère diminution de la consommation en 2020 et 2021, probablement attribuable aux effets de la pandémie. Par conséquent, il apparaît que cette variable n'entretient pas de relation linéaire évidente avec la consommation. Cette variable n'aura donc probablement pas d'influence sur la consommation.\n",
    "\n",
    "- `type`: Pour certains types de véhicules, la quantité de données disponibles est insuffisante, ce qui complique une évaluation fiable et précise de leur impact sur la consommation. Cette limitation justifie la nécessité de mener une analyse complémentaire dédiée à cette variable, comme détaillé dans la prochaine section intitulée \"Analyse par type de véhicule\". \n",
    "\n",
    "- `nombre_cylindres`: On observe que cette variable peut prendre 7 valeurs distinctes : [3, 4, 5, 6, 8, 10, 12]. Parmi celles-ci, trois valeurs (5, 10 et 12) ont chacune très peu de données. De plus, on remarque une tendance où l'augmentation du nombre de cylindres est associée à une augmentation de la consommation, suggérant une possible relation linéaire entre ces deux variables. \n",
    "\n",
    "- `cylindree` : On remarque une tendance où l'augmentation de la cylindree est associée à une augmentation de la consommation, suggérant une possible relation linéaire entre ces deux variables.\n",
    "\n",
    "- `transmission`: Les transmissions intégrale, propulsion et 4x4 présentent une distribution de consommation relativement similaire. En revanche, la transmission traction semble afficher une tendance à une consommation inférieure par rapport aux autres.\n",
    "\n",
    "- `boite`: Le type de boîte de vitesses ne semble pas influencer significativement la consommation, car la distribution de la consommation pour les boîtes automatiques est globalement similaire à celle des boîtes manuelles.\n",
    "\n",
    "- `volume_gaz` : La relation entre les deux variables semble linéaire ou même semble logarithmique. Cependant, on remarque qu'il y a beaucoup plus de données pour des volumes faibles que pour des volumes élevés.\n",
    "\n",
    "- `weight`: Étant donné que le poids prend en compte les différents types de véhicules, il est difficile d'analyser une relation directe entre le poids et la consommation. Malgré ça, pour le moment on ne voit pas de relation linéaire entre les deux variables.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse par `type` de véhicule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous poursuivons l'exploration en examinant les données par `type`. Cette étape vise à identifier des comportements spécifiques à chaque `type`. En regroupant les véhicules par transmission au sein de chaque `type`, nous calculons la `consommation` moyenne, le `volume_gaz` moyen et le nombre d'observations dans chaque groupe. Cela nous permet de mieux comprendre comment ces facteurs interagissent pour chaque `type` de véhicule et d'évaluer si le `type` ou la `transmission` influence significativement la `consommation`. Cette analyse guide ainsi la sélection des variables pertinentes pour le modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for type in unique(trainDataExploration.type)\n",
    "    println(type)\n",
    "    data_type = trainDataExploration[trainDataExploration.type .== type, :]\n",
    "    println(combine(groupby(data_type, :transmission), :consommation => mean, :volume_gaz => mean, nrow => :nrow))\n",
    "    println()\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans les tableaux précédents, nous constatons que, pour une voiture moyenne, une voiture compacte, une voiture minicompacte et une voiture_sous_compacte avec une transmission par traction, la consommation moyenne et le volume de gaz moyen sont plus faibles que pour les autres types de transmission. Cependant, pour les autres types de véhicules, ces valeurs restent similaires, quelle que soit la transmission. Ainsi, cette observation ne semble pas apporter de conclusions claires quant à une relation significative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous passons maintenant à une visualisation plus détaillée. Pour chaque `type` de véhicule, nous traçons la relation entre le `volume_gaz` et la `consommation`. Cette étape vise à observer s'il existe des tendances ou des corrélations spécifiques entre ces deux variables pour chaque `type`. Ces visualisations permettent de détecter des comportements distincts ou des patrons dans les données, ce qui peut orienter la sélection des variables explicatives ou révéler des transformations nécessaires pour améliorer la précision du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "\n",
    "for type in unique(trainDataExploration.type)\n",
    "    data_type = trainDataExploration[trainDataExploration.type .== type, :]\n",
    "    push!(plots, plot(\n",
    "        x=data_type.volume_gaz,\n",
    "        y=data_type.consommation,\n",
    "        Geom.point,\n",
    "        Guide.title(\"Type: $type\"),\n",
    "        Guide.xlabel(\"Volume Gaz\"),\n",
    "        Guide.ylabel(\"Consommation\")\n",
    "    ))\n",
    "end\n",
    "\n",
    "set_default_plot_size(10cm, 10cm)\n",
    "\n",
    "for i in 1:length(plots)\n",
    "    display(plots[i])\n",
    "end "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Étant donné qu'il y a très peu de données pour certains `type`, il est difficile d'analyser et d'identifier des tendances dans les graphiques ci-dessus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ajout variable : `general_type`\n",
    "\n",
    "L'ajout de la variable `general_type` dans les données d'exploration permet de regrouper les types spécifiques de véhicules en catégories plus générales telles que \"voiture\", \"VUS\", \"camionnette\" ou \"break\". Ces catégories sont basées sur le type de carrosserie de la voiture. Cela simplifie l'analyse en réduisant la granularité de la variable `type`, qui contient de nombreuses sous-catégories. En utilisant ces regroupements, on peut mieux voir les tendances globales et réduire la complexité du modèle de prédiction, tout en conservant les différences majeures entre les groupes de véhicules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_type_dict = Dict(\n",
    "    \"voiture_moyenne\" => \"voiture\", \n",
    "    \"VUS_petit\" => \"VUS\", \n",
    "    \"voiture_compacte\" => \"voiture\", \n",
    "    \"voiture_deux_places\" => \"voiture\", \n",
    "    \"voiture_minicompacte\" => \"voiture\", \n",
    "    \"VUS_standard\" => \"VUS\", \n",
    "    \"monospace\" => \"camionnette\", \n",
    "    \"voiture_sous_compacte\" => \"voiture\", \n",
    "    \"camionnette_petit\" => \"camionnette\", \n",
    "    \"break_petit\" => \"break\", \n",
    "    \"voiture_grande\" => \"voiture\", \n",
    "    \"camionnette_standard\" => \"camionnette\", \n",
    "    \"break_moyen\" => \"break\")\n",
    "\n",
    "trainDataExploration[!, :general_type] = [general_type_dict[t] for t in trainDataExploration[!, :type]]\n",
    "unique(trainDataExploration[!, :general_type])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinons maintenant le `volume_gaz` par rapport à la `consommation` pour chacun des `general_type`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots = []\n",
    "\n",
    "for general_type in unique(trainDataExploration.general_type)\n",
    "    data_type = trainDataExploration[trainDataExploration.general_type .== general_type, :]\n",
    "    push!(plots, plot(\n",
    "        x=data_type.volume_gaz,\n",
    "        y=data_type.consommation,\n",
    "        Geom.point,\n",
    "        Guide.title(\"General Type: $general_type\"),\n",
    "        Guide.xlabel(\"Volume Gaz\"),\n",
    "        Guide.ylabel(\"Consommation\")\n",
    "    ))\n",
    "end\n",
    "\n",
    "set_default_plot_size(10cm, 10cm)\n",
    "\n",
    "for i in 1:length(plots)\n",
    "    display(plots[i])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les graphiques ci-dessus semble montrer une tendance linéaire, où une augmentation du volume de gaz (x) semble être associée à une hausse de la consommation (y). Ainsi, la variable `general_type` pourrait être une variable explicative pertinente pour comprendre la consommation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation des variables explicatives: inclusion des variables qualitatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'encodage des variables explicatives qualitatives `general_type`, `transmission` et `boite` est essentiel afin d'être en mesure de les transformer en format numérique et de pouvoir les intégrer dans nos modèles pour effectuer la prédiction.\n",
    "\n",
    "Nous avons décidé de faire un encodage One-Hot Encoding pour représenter chaque catégorie de manière binaire (0 ou 1), ce qui permet de conserver la distinction entre les différentes catégories tout en évitant de leur attribuer une hiérarchie implicite."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "removeRows (generic function with 1 method)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function encode(data, column)\n",
    "    for c in unique(data[!, column])\n",
    "        data[!, Symbol(c)] = ifelse.(data[!, column] .== c, 1, 0)\n",
    "    end\n",
    "    return data\n",
    "end\n",
    "\n",
    "function encode_data(data)\n",
    "    encoded_data = deepcopy(data)\n",
    "    encoded_data = encode(encoded_data, :general_type)\n",
    "    encoded_data = encode(encoded_data, :transmission)\n",
    "    encoded_data = encode(encoded_data, :boite)\n",
    "    return encoded_data\n",
    "end\n",
    "\n",
    "function removeRows(data)\n",
    "    return select!(data, Not([:type, :transmission, :boite, :general_type,]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainDataExplorationEncoded = encode_data(trainDataExploration)\n",
    "removeRows(trainDataExplorationEncoded)\n",
    "first(trainDataExplorationEncoded, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse de colinéarité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colinéarité survient lorsque deux ou plusieurs variables sont fortement corrélées, ce qui peut causer des problèmes lors de l'ajustement de modèles statistiques ou d'apprentissage automatique. Plus précisément, une forte colinéarité peut :\n",
    "- Rendre difficile l'interprétation des coefficients dans un modèle.\n",
    "- Affecter la stabilité numérique des algorithmes de régression.\n",
    "\n",
    "C'est pourquoi cette analyse est essentiel pour la précision de notre modèle. Pour identifier les variables colinéaires, nous calculons une matrice de corrélation pour les variables numériques et repérons les paires dont la corrélation absolue dépasse un certain seuil (ici 0,8). Ceci nous guidera dans nos décisions futures en face aux variables explicatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluer_colinearite(data, seuil)\n",
    "    numerical_data = select(data, findall(x -> eltype(x) <: Number, eachcol(data)))\n",
    "    \n",
    "    correlation_matrix = cor(Matrix(numerical_data))\n",
    "    \n",
    "    variables_colineaires = []\n",
    "    valeur_R2 = []\n",
    "    \n",
    "    for i in 1:size(correlation_matrix, 1)\n",
    "        for j in (i + 1):size(correlation_matrix, 2)\n",
    "            R = abs(correlation_matrix[i, j])\n",
    "            if R >= seuil\n",
    "                push!(variables_colineaires, (names(numerical_data)[i], names(numerical_data)[j]))\n",
    "                push!(valeur_R2, R^2)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return correlation_matrix, variables_colineaires, valeur_R2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function calculate_vif(r_squared)\n",
    "    vif = (1 / (1 - r_squared))\n",
    "    return vif\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix, variables_colineaires, valeur_R2 = evaluer_colinearite(trainDataExplorationEncoded, 0.8)\n",
    "\n",
    "println(\"Matrice de corrélation :\")\n",
    "println(correlation_matrix)\n",
    "\n",
    "println(\"\\nPaires de variables susceptibles d'être colinéaires et leurs R² :\")\n",
    "for (paire, r2) in zip(variables_colineaires, valeur_R2)\n",
    "    vif = calculate_vif(r2)\n",
    "    println(\"Paire : $paire, VIF : $vif\")\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'analyse de colinéarité réalisée ci-dessus sur les données a permis de détecter plusieurs paires de variables susceptibles d’être fortement corrélées, notamment `nombre_cylindres`, `cylindree` et `volume_gaz`.En effet, le calcul des VIF confirme une très forte colinéarité sur ces trois paramètres (VIF>=10).  Ce qu’on en retire est que ces variables pourraient introduire de la redondance dans les modèles prédictifs, ce qui peut affecter la stabilité et l’interprétabilité des résultats. Étant donné que la variable d'intérêt est la consommation, il serait pertinent de considérer la suppression de certaines de ces variables colinéaires afin de simplifier le modèle et éviter les problèmes liés à la multicolinéarité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Données uniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons remarqué que, parmi les 396 données, de nombreuses possèdent les mêmes caractéristiques, c'est-à-dire que leurs variables explicatives sont identiques, à l’exception de l’année. Comme mentionné dans l’analyse des graphiques de la section \"Recherche de relations entre les variables explicatives et la variable d’intérêt\", nous n'avons pas observé de relation entre la consommation et l'année. Ainsi, nous sélectionnons toutes les colonnes de l’ensemble d’entraînement, sauf `année` et `consommation`, afin de regrouper les données ayant des caractéristiques similaires. L’objectif est ensuite de calculer la moyenne de la consommation pour chaque groupe ainsi formé, puis de former un ensemble ayant que les données uniques. \n",
    "\n",
    "Il semble logique d'opter pour la moyenne dans ce cas, pusique pour des X identiques avec des valeurs de y différentes, si notre objectif est de minimiser le RMSE:\n",
    "\n",
    "$RMSE = \\sqrt{\\sum_{i = 1}^{n}{(y_i - \\hat{y_i})^2}} = ||{y - \\hat{y}}||$\n",
    "\n",
    "si on veut minismiser cette quantié pour une constante $\\hat{y}$ tel que $RMSE$ est minimisé\n",
    "\n",
    "$\\frac{\\partial}{\\partial\\hat{y}} \\sqrt{\\sum_{i = 1}^{n}{(y_i - \\hat{y})^2}} = 0$\n",
    "\n",
    "par la loi de différentiation en chaine:\n",
    "\n",
    "$ \\sqrt{ \\frac{\\partial}{\\partial\\hat{y}} \\sum_{i = 1}^{n}{(y_i - \\hat{y})^2}} * \\frac{1}{2 * \\sum_{i = 1}^{n}{(y_i - \\hat{y})^2}} = 0$\n",
    "\n",
    "ou bien\n",
    "\n",
    "$ \\sqrt{ \\frac{\\partial}{\\partial\\hat{y}} \\sum_{i = 1}^{n}{(y_i^2 + \\hat{y}^2 - 2 * y_i * \\hat{y})}} = 0 $\n",
    "\n",
    "$ \\sqrt{ \\frac{\\partial}{\\partial\\hat{y}}( n\\hat{y}^2 +  \\sum_{i = 1}^{n}{y_i^2} - \\sum_{i = 1}^{n}2y_i\\hat{y})} = 0 $\n",
    "\n",
    "$ \\sqrt{ 2n\\hat{y}  - \\sum_{i = 1}^{n}2y_i} = 0 $\n",
    "\n",
    "$2n\\hat{y} = 2\\sum_{i = 1}^{n}y_i$\n",
    "\n",
    "$\\hat{y} = \\frac{\\sum_{i = 1}^{n}y_i}{n} = \\bar{y}$\n",
    "\n",
    "La moyenne est donc l'estimateur qui minimise le RMSE pour nos observations X identiques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_unique_data (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_unique_data(data)\n",
    "    data_without_consommation = select(data, Not(:consommation, :annee))\n",
    "\n",
    "\n",
    "    unique_data = combine(groupby(data, names(data_without_consommation)), :consommation => mean)\n",
    "    rename!(unique_data, :consommation_mean => :consommation)\n",
    "    return unique_data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueTrainDataExploration = get_unique_data(trainDataExploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut observer que nous avons maintenant 145 données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examinons les relations entre la consommation et les variables explicatives pour déterminer si des changements significatifs sont observés par rapport aux graphiques présentés dans la section \"Recherche de relations entre les variables explicatives et la variable d’intérêt\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [:type, :nombre_cylindres, :cylindree, :transmission, :boite, :volume_gaz]\n",
    "\n",
    "plots = [\n",
    "    Gadfly.plot(\n",
    "        uniqueTrainDataExploration,\n",
    "        x=var,\n",
    "        y=:consommation,\n",
    "        Geom.point,\n",
    "        Guide.xlabel(string(var)),\n",
    "        Guide.ylabel(\"consommation\")\n",
    "    ) for var in variables\n",
    "]\n",
    "\n",
    "set_default_plot_size(35cm, 35cm)\n",
    "p = reshape(plots, (3,2))\n",
    "gridstack(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les graphiques ci-dessus présentent une allure similaire à ceux de la section \"Recherche de relations entre les variables explicatives et la variable d’intérêt\". Cela dit, il pourrait être intéressant de tester avec les modèles en ne conservant que les données uniques. Cette approche permet de simplifier le dataset en réduisant la redondance des observations ayant les mêmes caractéristiques explicatives. Cela pourrait faciliter l’apprentissage du modèle tout en améliorant son efficacité et en limitant les risques d'erreurs liés à des consommations différentes pour des données identiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des données aberrantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour l'analyse des données aberrantes, nous avons commencé par faire la ségrégation des données abberrantes à l'aide de la méthode classique des quantiles sur le graphique de la `cylindree` en fonction de la `consommation`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_outliers(column)\n",
    "    Q1 = quantile(column, 0.25)\n",
    "    Q3 = quantile(column, 0.75) \n",
    "    IQR = Q3 - Q1                \n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    println(\"Column bounds -> Lower: \", lower_bound, \", Upper: \", upper_bound, \", Q1: \", Q1, \", Q3: \", Q3, \", IQR: \", IQR)\n",
    "    return findall(x -> x < lower_bound || x > upper_bound, column)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_outliers_ind_quantile (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function get_outliers_ind_quantile(data, x_col, y_col)\n",
    "    x = data[!, x_col]\n",
    "    y = data[!, y_col]\n",
    "\n",
    "    outlier_indices_x = compute_outliers(x)\n",
    "    outlier_indices_y = compute_outliers(y)\n",
    "\n",
    "    combined_outlier_indices = vcat(outlier_indices_x, outlier_indices_y)\n",
    "    return combined_outlier_indices\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_outliers(data, outliers_indices)\n",
    "    outliers = data[outliers_indices, :]\n",
    "    return outliers\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette méthode va visualiser les données abberrantes (points noirs) et nous allons voir que ces résultas sont plutot mélancolique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_outliers_quantile (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function plot_outliers_quantile(uniqueD)\n",
    "    outliers_indices = get_outliers_ind_quantile(uniqueD, :cylindree, :consommation)\n",
    "    outliers_quantile = get_outliers(uniqueD, outliers_indices)\n",
    "   \n",
    "    layer_original = layer(x=uniqueD.cylindree, y=uniqueD.consommation, color=uniqueD.type)\n",
    "    layer_quantile_outliers = layer(x=outliers_quantile.cylindree, y=outliers_quantile.consommation, Theme(default_color=\"black\"))\n",
    "    set_default_plot_size(15cm, 15cm)\n",
    "    \n",
    "    display(plot(layer_quantile_outliers, layer_original, Guide.xlabel(\"Cylindree\"), Guide.ylabel(\"Consommation\"), Guide.title(\"Original Data with Outliers\")))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_outliers_quantile(uniqueTrainDataExploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats étant trop stricte sur les types plus consommateurs, nous avons plutôt opté pour une régression linéaire avec un seuil choisi. Ce choix de régression linéaire a été fait, car comme vu ci-dessus, suit une tendance linéaire. On commence par trouver les indices (lignes) des données aberrantes avec la méthode get_outliers_ind_regression_lin et linear_regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_outliers_ind_regression_lin(data, x_col, y_col; threshold=2.5)\n",
    "    slope, intercept = linear_regression(data, x_col, y_col)\n",
    "    \n",
    "    x = data[!, x_col]\n",
    "    y = data[!, y_col]\n",
    "    \n",
    "    y_pred = slope .* x .+ intercept\n",
    "    \n",
    "    residuals = abs.(y .- y_pred)\n",
    "    \n",
    "    residuals_std = std(residuals)\n",
    "    \n",
    "    outlier_indices = findall(residuals .> threshold * residuals_std)\n",
    "    \n",
    "    outliers = data[outlier_indices, :]\n",
    "    \n",
    "    return outlier_indices\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function linear_regression(data, x_col, y_col)\n",
    "    x = data[!, x_col]\n",
    "    y = data[!, y_col]\n",
    "    \n",
    "    n = length(x)\n",
    "    if n == 0\n",
    "        error(\"Cannot compute linear regression with zero elements.\")\n",
    "    end\n",
    "    \n",
    "    x_mean = mean(x)\n",
    "    y_mean = mean(y)\n",
    "    \n",
    "    slope = sum((x .- x_mean) .* (y .- y_mean)) / sum((x .- x_mean).^2)\n",
    "    intercept = y_mean - slope * x_mean\n",
    "    \n",
    "    return slope, intercept\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De plus, une méthode pour les séparer des données régulières (remove_outliers_regression_lin):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function remove_outliers_regression_lin(data::DataFrame, x_col::Symbol, y_col::Symbol; threshold=2.5)\n",
    "    outlier_indices = get_outliers_ind_regression_lin(data, x_col, y_col, threshold=threshold)\n",
    "\n",
    "    keep_mask = trues(nrow(data))\n",
    "    \n",
    "    if !isempty(outlier_indices)\n",
    "        keep_mask[outlier_indices] .= false\n",
    "    end\n",
    "\n",
    "    cleaned_data = data[keep_mask, :]\n",
    "    \n",
    "    return cleaned_data\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dernièrement, une méthode pour visualiser les données avant (points noirs) et après le retrait des données aberrantes (plot_outliers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "function plot_outliers(uniqueD)\n",
    "    outliers_indices = get_outliers_ind_regression_lin(uniqueD, :cylindree, :consommation)\n",
    "    outliers_regression = get_outliers(uniqueD, outliers_indices)\n",
    "   \n",
    "    slope, intercept = linear_regression(uniqueD, :cylindree, :consommation)\n",
    "    regression_line_y = slope .* uniqueD.cylindree .+ intercept\n",
    "   \n",
    "    layer_original = layer(x=uniqueD.cylindree, y=uniqueD.consommation, color=uniqueD.type)\n",
    "    layer_linear_regression = layer(x=uniqueD.cylindree, y=regression_line_y, Geom.line, Theme(default_color=\"green\"))\n",
    "    layer_regression_outliers = layer(x=outliers_regression.cylindree, y=outliers_regression.consommation, Geom.point, Theme(default_color=\"black\"))\n",
    "    set_default_plot_size(15cm, 15cm)\n",
    "    \n",
    "    display(plot(layer_regression_outliers, layer_original, layer_linear_regression, Guide.xlabel(\"Cylindree\"), Guide.ylabel(\"Consommation\"), Guide.title(\"Original Data with Outliers\")))\n",
    "   \n",
    "    cleaned_data = remove_outliers_regression_lin(uniqueD, :cylindree, :consommation, threshold=2.5)\n",
    "   \n",
    "    slope_cleaned, intercept_cleaned = linear_regression(cleaned_data, :cylindree, :consommation)\n",
    "    regression_line_y_cleaned = slope_cleaned .* cleaned_data.cylindree .+ intercept_cleaned\n",
    "   \n",
    "   layer_cleaned = layer(x=cleaned_data.cylindree, y=cleaned_data.consommation, color=cleaned_data.type, Theme(default_color=\"blue\"))\n",
    "   layer_linear_regression_cleaned = layer(x=cleaned_data.cylindree, y=regression_line_y_cleaned, Geom.line, Theme(default_color=\"green\"))\n",
    "   \n",
    "   display(plot(layer_cleaned, layer_linear_regression_cleaned, \n",
    "                Guide.xlabel(\"Cylindree\"), Guide.ylabel(\"Consommation\"), Guide.title(\"Cleaned Data with Regression Line\")))\n",
    "   \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_outliers(uniqueTrainDataExploration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette analyse et ségrégation des données abberrantes pourront nous être utile plus tard dans nos recherches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suite à l'exploration des données, nous allons construire un DataFrame avec toutes les variables explicatives que nous avons évaluer comme étant pertinente pour la prédiction de la consommation...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardisation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons standardisé les données numériques pour mettre toutes nos données sur la même échelle. De cette façon, on peut comparer leur importance relative. De plus, une variable ayant des valeurs très hautes comparées aux autres n'influencera pas les données de façon plus significative qu'elle le devrait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.139763088813657"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMSOMMATION_MEAN = mean(trainData.consommation)\n",
    "COMSOMMATION_STD = std(trainData.consommation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "standardize_data (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function standardize(data)\n",
    "    return (data .- mean(data)) ./ std(data)\n",
    "end\n",
    "\n",
    "function standardize_data(data)\n",
    "    stddata = deepcopy(data)\n",
    "   for col in names(stddata)\n",
    "        if eltype(stddata[!, col]) <: Number && col != \"id\"\n",
    "            stddata[!, col] = standardize(stddata[!, col])\n",
    "        end\n",
    "    end\n",
    "    return stddata\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_rows (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function add_rows(data)\n",
    "    data[!,:volume_gaz] = data[!,:nombre_cylindres] .* data[!,:cylindree]\n",
    "\n",
    "    #https://www.insurancenavy.com/average-car-weight/\n",
    "    #https://www.auto-tests.com/fr/lightest-weight/Wagon/all/\n",
    "    weight_dict = Dict(\"voiture_moyenne\" => 3300, \"VUS_petit\" => 3500, \"voiture_compacte\" => 2800, \"voiture_deux_places\" => 2800, \"voiture_minicompacte\" => 1500, \"VUS_standard\" => 5000, \"monospace\" => 4500, \"voiture_sous_compacte\" => 2600, \"camionnette_petit\" => 4200, \"break_petit\" => 2640, \"voiture_grande\" => 4400, \"camionnette_standard\" => 4700, \"break_moyen\" => 3300)\n",
    "    data[!, :weight] = [weight_dict[t] for t in data[!, :type]]\n",
    "\n",
    "    general_type_dict = Dict(\"voiture_moyenne\" => \"voiture\", \"VUS_petit\" => \"VUS\", \"voiture_compacte\" => \"voiture\", \"voiture_deux_places\" => \"voiture\", \"voiture_minicompacte\" => \"voiture\", \"VUS_standard\" => \"VUS\", \"monospace\" => \"camionnette\", \"voiture_sous_compacte\" => \"voiture\", \"camionnette_petit\" => \"camionnette\", \"break_petit\" => \"break\", \"voiture_grande\" => \"voiture\", \"camionnette_standard\" => \"camionnette\", \"break_moyen\" => \"break\")\n",
    "    data[!, :general_type] = [general_type_dict[t] for t in data[!, :type]]\n",
    "    \n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getStandardEncodedData (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function getStandardEncodedData(data)\n",
    "    data_copy = deepcopy(data)\n",
    "    standardised_data = get_unique_data(data_copy)\n",
    "    standardised_data = add_rows(data_copy)\n",
    "    standardised_data = standardize_data(data_copy)\n",
    "    standardised_data = encode_data(standardised_data)\n",
    "    standardised_data = removeRows(standardised_data)\n",
    "    \n",
    "    return standardised_data\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Évaluation des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calcul rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons évalué nos modèles avec la métrique rmse, car c'est celle-ci qui est utilisée pour évaluer nos prédictions dans le concours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rmse(y, prediction)\n",
    "    return sqrt(mean((prediction .- y).^2))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous avons calculé le rmse moyen en faisant une séparation aléatoire des données à chaque fois afin d'avoir une idée générale du rmse de chaque modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_rmse (generic function with 3 methods)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evaluate_rmse(data, model, nrange = 1000, test_size = 0.2)\n",
    "    n = 0\n",
    "    for i in range(0, 1, length=nrange)\n",
    "        train_data, test_data = train_test_split(data, test_size)\n",
    "        n += model(train_data, test_data)[1]\n",
    "    end\n",
    "    average_rmse = n/nrange\n",
    "    print(\"average rmse: \", average_rmse, \"\\n\")\n",
    "    return average_rmse\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation des ensemble d'entrainement et de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_test_split (generic function with 3 methods)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_test_split(data, test_size=0.2, shuffle=true)\n",
    "    n = size(data, 1)\n",
    "    test_size = floor(Int, n * test_size)\n",
    "    \n",
    "    if shuffle\n",
    "        indices = randperm(n)\n",
    "    else\n",
    "        indices = 1:n\n",
    "    end\n",
    "    \n",
    "    test_indices = indices[1:test_size]\n",
    "    train_indices = indices[test_size+1:end]\n",
    "    \n",
    "    train_data = data[train_indices, :]\n",
    "    test_data = data[test_indices, :]\n",
    "    \n",
    "    return train_data, test_data\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Les différents modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici une liste des toutes les modèles prédictifs que nous avons implémenter et tester afin d'obtenir les meilleures prédictions de consommation d'essence:\n",
    "- Régression\n",
    "- Régression ridge\n",
    "- Régression lasso\n",
    "- Régression polynomiale\n",
    "- Régression SVD\n",
    "- Arbres de classification\n",
    "- Autres?\n",
    "\n",
    "Voici leurs implémentations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression linéaire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "regression (generic function with 2 methods)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function regression(training_data, test_data = nothing)\t\n",
    "    X_train =  Matrix(training_data[:, Not(:consommation, :id)])\n",
    "    y_train = training_data[:, :consommation]\n",
    "\n",
    "    beta = X_train \\ y_train\n",
    "\n",
    "    rmseval = 0.0\n",
    "    if test_data != nothing\n",
    "        X_test = Matrix(test_data[:, Not(:consommation, :id)])\n",
    "        y_test = test_data[:, :consommation]\n",
    "        y_predict =  X_test * beta\n",
    "        y_predict = (y_predict .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        y_test = (y_test .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        rmseval = rmse(y_test, y_predict)\n",
    "    end\n",
    "    \n",
    "    return rmseval, beta\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average rmse: 0.9475703528621615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9475703528621615"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rmse(getStandardEncodedData(trainData), regression)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ridge_regression (generic function with 3 methods)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ridge_regression(training_data, test_data = nothing, lambda=0.5)\n",
    "    X_train = Matrix(training_data[:, Not([:consommation, :id])])\n",
    "    y_train = training_data[:, :consommation]\n",
    "    beta = (X_train'X_train + lambda*I)\\X_train'y_train\n",
    "\n",
    "    rmseval = 0.0\n",
    "    if test_data != nothing\n",
    "        X_test = Matrix(test_data[:, Not(:consommation, :id)])\n",
    "        y_test = test_data[:, :consommation]\n",
    "        ychap =  X_test * beta\n",
    "        ychap = (ychap .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        y_test = (y_test .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        rmseval = rmse(y_test, ychap)\n",
    "    end\n",
    "    return rmseval, beta\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average rmse: 0.9565591365482474\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9565591365482474"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rmse(getStandardEncodedData(trainData), ridge_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Régression SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svd_regression (generic function with 2 methods)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function svd_regression(training_data, test_data = nothing)\n",
    "    X_train = Matrix(training_data[:, Not([:consommation, :id])])\n",
    "    y_train = training_data[:, :consommation]\n",
    "    \n",
    "    U, S, V = svd(X_train)\n",
    "\n",
    "    beta = V' * Diagonal([s > 1e-10 ? 1/s : 0 for s in S]) * U' * y_train\n",
    "\n",
    "    rmseval = 0.0\n",
    "    if test_data != nothing\n",
    "        X_test = Matrix(test_data[:, Not(:consommation,:id)])\n",
    "        y_test = test_data[:, :consommation]\n",
    "        ychap =  X_test * beta\n",
    "        ychap = (ychap .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        y_test = (y_test .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        rmseval = rmse(y_test, ychap)\n",
    "    end\n",
    "    return rmseval, beta\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.466190563236575"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average rmse: 2.466190563236575\n"
     ]
    }
   ],
   "source": [
    "evaluate_rmse(getStandardEncodedData(trainData), svd_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### régression polynomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "polynomial_regression (generic function with 3 methods)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function construct_structure(x::Matrix{<:Real}, order::Int)\n",
    "    n, m = size(x)\n",
    "    poly_terms = [x[:, j].^p for j in 1:m, p in 0:order]\n",
    "    X = hcat(poly_terms...)\n",
    "    return X\n",
    "end\n",
    "\n",
    "function polynomial_regression(training_data, test_data = nothing, degree = 3)\n",
    "    X_train = construct_structure(Matrix(training_data[:, Not([:consommation, :id])]), degree)\n",
    "    y_train = training_data[:, :consommation]\n",
    "\n",
    "    beta = X_train \\ y_train\n",
    "\n",
    "    rmseval = 0.0\n",
    "\n",
    "    if test_data != nothing\n",
    "        X_test = construct_structure(Matrix(test_data[:, Not([:consommation, :id])]), degree)\n",
    "        y_test = test_data[:, :consommation]\n",
    "        ychap = X_test * beta\n",
    "        ychap = (ychap .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        y_test = (y_test .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "\n",
    "        rmseval = rmse(y_test, ychap)\n",
    "    end\n",
    "\n",
    "    return rmseval, beta\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average rmse: 0.9120975660802773\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9120975660802773"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_rmse(getStandardEncodedData(trainData), polynomial_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparaison des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suite à plusieurs tests de chacune d'entrée elle le modèles ayant proposer les meilleures prédictions est ... parce que ... À compléter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion et amélioration"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
