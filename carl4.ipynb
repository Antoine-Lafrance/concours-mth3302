{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MTH3302 - Méthodes probabilistes et statistiques pour I.A.\n",
    "#### Polytechnique Montréal\n",
    "### Projet A2024\n",
    "----\n",
    "Équipe T - TODO\n",
    "### Objectif\n",
    "Prédiction de **la consommation en carburant de voitures récentes**.\n",
    "\n",
    "### Données\n",
    "Le jeu de données contient pour presque 400 véhicule, la consommation moyenne en L/100km, l'année de frabrication, le type de véhicule, le nombre de cylindre, cylindree, la transmission et la boite.\n",
    "\n",
    "- `train.csv` est l'ensemble d'entraînement\n",
    "- `test.csv` est l'ensemble de test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importation des librairies utilisées dans le calepin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "// TODO: à enlever à la fin:\n",
    "\n",
    "Pour importer librairies:\n",
    "using Pkg\n",
    "Pkg.add([\"CSV\", \"DataFrames\", \"Combinatorics\", \"Gadfly\", \"Distributions\"], ...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Pkg; Pkg.add(\"Plots\")\n",
    "# import Pkg; Pkg.add(\"DecisionTree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Statistics, Dates, Gadfly, LinearAlgebra, DecisionTree,Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "standardize_data (generic function with 1 method)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function standardize(data)\n",
    "    return (data .- mean(data)) ./ std(data)\n",
    "end\n",
    "\n",
    "function standardize_data(data)\n",
    "    stddata = deepcopy(data)\n",
    "   for col in names(stddata)\n",
    "        if eltype(stddata[!, col]) <: Number && col != \"id\"\n",
    "            stddata[!, col] = standardize(stddata[!, col])\n",
    "        end\n",
    "    end\n",
    "    return stddata\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "encode_data (generic function with 1 method)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function encode(data, column)\n",
    "    for c in unique(data[!, column])\n",
    "        data[!, Symbol(c)] = ifelse.(data[!, column] .== c, 1, 0)\n",
    "    end\n",
    "    return data\n",
    "end\n",
    "\n",
    "function encode_data(data)\n",
    "    encoded_data = deepcopy(data)\n",
    "    encoded_data = encode(encoded_data, :general_type)\n",
    "    encoded_data = encode(encoded_data, :transmission)\n",
    "    encoded_data = encode(encoded_data, :boite)\n",
    "    return encoded_data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "removeRows (generic function with 1 method)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function removeRows(data)\n",
    "    return select!(data, Not([:type, :transmission, :boite, :nombre_cylindres, :annee]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "add_rows (generic function with 1 method)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function add_rows(data)\n",
    "    # data[!,:volume_gaz] = data[!,:nombre_cylindres] .* data[!,:cylindree]\n",
    "\n",
    "    # https://www.insurancenavy.com/average-car-weight/\n",
    "    # https://www.auto-tests.com/fr/lightest-weight/Wagon/all/\n",
    "    # weight_dict = Dict(\"voiture_moyenne\" => 3300, \"VUS_petit\" => 3500, \"voiture_compacte\" => 2800, \"voiture_deux_places\" => 2800, \"voiture_minicompacte\" => 1500, \"VUS_standard\" => 5000, \"monospace\" => 4500, \"voiture_sous_compacte\" => 2600, \"camionnette_petit\" => 4200, \"break_petit\" => 2640, \"voiture_grande\" => 4400, \"camionnette_standard\" => 4700, \"break_moyen\" => 3300)\n",
    "    # data[!, :weight] = [weight_dict[t] for t in data[!, :type]]\n",
    "\n",
    "    # general_type_dict = Dict(\"voiture_moyenne\" => \"voiture\", \"VUS_petit\" => \"VUS\", \"voiture_compacte\" => \"voiture\", \"voiture_deux_places\" => \"voiture\", \"voiture_minicompacte\" => \"voiture\", \"VUS_standard\" => \"VUS\", \"monospace\" => \"camionnette\", \"voiture_sous_compacte\" => \"voiture\", \"camionnette_petit\" => \"camionnette\", \"break_petit\" => \"break\", \"voiture_grande\" => \"voiture\", \"camionnette_standard\" => \"camionnette\", \"break_moyen\" => \"break\")\n",
    "    # data[!, :general_type] = [general_type_dict[t] for t in data[!, :type]]\n",
    "    \n",
    "    # display(plot(data, x=:general_type, y=:consommation, color=:type))\n",
    "    # println(combine(groupby(data, :type), nrow => :count))\n",
    "    return data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "getStandardEncodedData (generic function with 1 method)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function getStandardEncodedData(data)\n",
    "    data_copy = deepcopy(data)\n",
    "    standardised_data = add_rows(data_copy)\n",
    "    standardised_data = standardize_data(data_copy)\n",
    "    # standardised_data = encode_data(standardised_data)\n",
    "    standardised_data = removeRows(standardised_data)\n",
    "    \n",
    "    print(standardised_data)\n",
    "    return standardised_data\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rmse (generic function with 1 method)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rmse(y, ychap)\n",
    "    return sqrt(mean((ychap .- y).^2))\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rsquared (generic function with 1 method)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rsquared(y, ychap)\n",
    "    ss_total = sum((y .- mean(y)).^2)\n",
    "    ss_res = sum((y .- ychap).^2)\n",
    "    return ss_res / ss_total\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "train_test_split (generic function with 3 methods)"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function train_test_split(data, test_size=0.2, shuffle=true)\n",
    "    n = size(data, 1)\n",
    "    test_size = floor(Int, n * test_size)\n",
    "    \n",
    "    if shuffle\n",
    "        indices = randperm(n)\n",
    "    else\n",
    "        indices = 1:n\n",
    "    end\n",
    "    \n",
    "    test_indices = indices[1:test_size]\n",
    "    train_indices = indices[test_size+1:end]\n",
    "    \n",
    "    train_data = data[train_indices, :]\n",
    "    test_data = data[test_indices, :]\n",
    "    \n",
    "    return train_data, test_data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25-element Vector{Float64}:\n",
       " 13.8358823529412\n",
       "  9.80041666666667\n",
       " 11.7605\n",
       " 13.0672222222222\n",
       "  7.3503125\n",
       "  7.58741935483871\n",
       " 11.2004761904762\n",
       " 14.700625\n",
       " 12.3794736842105\n",
       " 10.6913636363636\n",
       "  9.4084\n",
       " 15.6806666666667\n",
       "  8.71148148148148\n",
       "  8.11068965517241\n",
       " 10.2265217391304\n",
       "  7.84033333333333\n",
       "  8.40035714285714\n",
       "  9.04653846153846\n",
       " 16.8007142857143\n",
       "  6.91794117647059\n",
       "  6.35702702702703\n",
       "  4.52326923076923\n",
       "  7.12757575757576\n",
       "  4.90020833333333\n",
       "  6.53361111111111"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData = CSV.read(\"./data/train.csv\", DataFrame)\n",
    "testData = CSV.read(\"./data/test.csv\", DataFrame)\n",
    "trainData.consommation = parse.(Float64,replace.(trainData.consommation, \",\" => \".\"))\n",
    "trainData.cylindree = parse.(Float64,replace.(trainData.cylindree, \",\" => \".\"))\n",
    "testData.cylindree = parse.(Float64,replace.(testData.cylindree, \",\" => \".\"))\n",
    "\n",
    "\n",
    "COMSOMMATION_MEAN = mean(trainData.consommation)\n",
    "COMSOMMATION_STD = std(trainData.consommation)\n",
    "trainData[!, :id] = 1:nrow(trainData)\n",
    "testData[!, :id] = 1:nrow(testData)\n",
    "\n",
    "possibles = unique(trainData.consommation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_rmse (generic function with 1 method)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evaluate_rmse(data)\n",
    "    nrange = 1000\n",
    "    n = 0\n",
    "    for i in range(0, 1, length=nrange)\n",
    "        n += regression(data)[1]\n",
    "    end\n",
    "    print(\"average rmse for regression: \", n/nrange, \"\\n\")\n",
    "\n",
    "    # n = 0\n",
    "    # for i in range(0, 1, length=nrange)\n",
    "    #     n += ridge_regression(data, 0.1, 0.05)[1]\n",
    "    # end\n",
    "    # print(\"average rmse for ridge: \", n/nrange, \"\\n\")\n",
    "\n",
    "    # n = 0\n",
    "    # for i in range(0, 1, length=nrange)\n",
    "    #     n += svd_regression(data, 0.05)[1]\n",
    "    # end\n",
    "    # print(\"average rmse for svd: \", n/nrange, \"\\n\")\n",
    "\n",
    "    # nrange = 1000\n",
    "    # n = 0\n",
    "    # for i in range(0, 1, length=nrange)\n",
    "    #     n += polynomial_regression(data,2, 0.05)[1]\n",
    "    # end\n",
    "    # print(\"average rmse for polynomial regression: \", n/nrange, \"\\n\")\n",
    "\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "format_file (generic function with 1 method)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function remise(prediction)\n",
    "    id = 1:150\n",
    "    df_pred = DataFrame(id=id, consommation=prediction)\n",
    "\n",
    "   format_file(df_pred)\n",
    "end\n",
    "\n",
    "function format_file(predictions)\n",
    "    println(predictions)\n",
    "    current_time = Dates.format(now(), \"yyyy-mm-dd_HH-MM-SS\")\n",
    "    file_name = \"benchmark_\" * current_time * \".csv\"\n",
    "    CSV.write(\"./soumissions_potentielles/\" *file_name, predictions)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# findnearest(A::Vector{Float64},t::Float64) = A[findmin(broadcast(abs,A.-t))[2]]\n",
    "\n",
    "# function findnearest(A::Vector{Float64},t::Float64)\n",
    "#     nearest_value = A[1]\n",
    "#     smallest_diff = abs(A[1] - t)\n",
    "#     for value in A\n",
    "#         diff = abs(value - t)\n",
    "#         if diff < smallest_diff\n",
    "#             smallest_diff = diff\n",
    "#             nearest_value = value\n",
    "#         end\n",
    "#     end\n",
    "#     if smallest_diff > 0.3\n",
    "#         # println(\"Warning: the nearest value is \", nearest_value, \" the value was \", t,\" with a difference of \", smallest_diff)\n",
    "#     end\n",
    "#     return nearest_value\n",
    "    \n",
    "# end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "predict_with_dups (generic function with 1 method)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_unique_data(data, columns_to_compare)\n",
    "    unique_data = combine(groupby(data, columns_to_compare), :consommation => mean)\n",
    "    rename!(unique_data, :consommation_mean => :consommation)\n",
    "    return unique_data\n",
    "end\n",
    "\n",
    "function find_pairs(data_train, data_predict, columns_to_compare)\n",
    "    train_data_without_consommation = select(data_train, Not(:consommation))\n",
    "    # print(train_data_without_consommation)\n",
    "    predict_data_without_annee = select(data_predict, Not(:annee))\n",
    "    # print(predict_data_without_annee)\n",
    "\n",
    "    println(names(train_data_without_consommation))\n",
    "\n",
    "    common_values = innerjoin(data_train, predict_data_without_annee, on=columns_to_compare)\n",
    "\n",
    "    println(common_values.id)\n",
    "    # print(common_values)\n",
    "    return common_values\n",
    "end\n",
    "\n",
    "function find_differents(data_train, data_predict)\n",
    "    different_values = antijoin(data_predict, data_train, on=COLUMNS_TO_COMPARE)\n",
    "    return different_values\n",
    "    \n",
    "end\n",
    "\n",
    "function predict_with_dups(data_train, data_predict, raw_data_train, raw_data_predict)\n",
    "    pairs = find_pairs(raw_data_train, raw_data_predict)\n",
    "    pairs = select(pairs, [:id, :consommation])\n",
    "\n",
    "    # println(first(raw_data_train,1))\n",
    "    # println(first(raw_data_predict,1))\n",
    "\n",
    "    # println(pairs)\n",
    "\n",
    "    different_values = find_differents(raw_data_train, raw_data_predict)\n",
    "    # println(different_values)\n",
    "\n",
    "    beta = regression(data_train, 0.0)[2]\n",
    "\n",
    "    data_predict = getStandardEncodedData(different_values[!, Not(:id)])\n",
    "\n",
    "\n",
    "    data_predict = Matrix(data_predict[:, names(data_train[:, Not(:consommation)])])\n",
    "    println(data_predict)\n",
    "\n",
    "    prediction_differents = data_predict * beta\n",
    "\n",
    "    # print(prediction)\n",
    "\n",
    "\n",
    "    prediction_differents = (prediction_differents .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "\n",
    "    prediction_differents = DataFrame(id=different_values.id, consommation=prediction_differents)\n",
    "\n",
    "    # print(prediction_differents)\n",
    "    # print(pairs)\n",
    "\n",
    "    prediction = vcat(pairs, prediction_differents)\n",
    "    prediction = sort(prediction, :id)\n",
    "    # println(prediction)\n",
    "\n",
    "    # print(prediction)\n",
    "    return prediction\n",
    "end\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "linear_regression (generic function with 1 method)"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function linear_regression(data, x_col, y_col)\n",
    "    # Extract x and y data from the DataFrame\n",
    "    x = data[!, x_col]\n",
    "    y = data[!, y_col]\n",
    "    \n",
    "    # Ensure there is enough data for the calculation\n",
    "    n = length(x)\n",
    "    if n == 0\n",
    "        error(\"Cannot compute linear regression with zero elements.\")\n",
    "    end\n",
    "    \n",
    "    # Calculate the mean values\n",
    "    x_mean = mean(x)\n",
    "    y_mean = mean(y)\n",
    "    \n",
    "    # Calculate slope and intercept for linear regression\n",
    "    slope = sum((x .- x_mean) .* (y .- y_mean)) / sum((x .- x_mean).^2)\n",
    "    intercept = y_mean - slope * x_mean\n",
    "    \n",
    "    return slope, intercept\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_outliers_ind_regression_lin (generic function with 1 method)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "function get_outliers_ind_regression_lin(data, x_col, y_col; threshold=2.5)\n",
    "    slope, intercept = linear_regression(data, x_col, y_col)\n",
    "    \n",
    "    x = data[!, x_col]\n",
    "    y = data[!, y_col]\n",
    "    \n",
    "    y_pred = slope .* x .+ intercept\n",
    "    \n",
    "    residuals = abs.(y .- y_pred)\n",
    "    \n",
    "    residuals_std = std(residuals)\n",
    "    \n",
    "    outlier_indices = findall(residuals .> threshold * residuals_std)\n",
    "    \n",
    "\n",
    "    for idx in outlier_indices\n",
    "        # println(\"Outlier detected at row $idx: \", \"x = \", x[idx], \", y = \", y[idx], \", Residual = \", residuals[idx])\n",
    "    end\n",
    "\n",
    "    outliers = data[outlier_indices, :]\n",
    "    \n",
    "    return outlier_indices\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_outliers_regression_lin(data, outliers_indices)\n",
    "    outliers = data[outliers_indices, :]\n",
    "    return outliers\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "remove_outliers_regression_lin (generic function with 1 method)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function remove_outliers_regression_lin(data::DataFrame, x_col::Symbol, y_col::Symbol; threshold=2.5)\n",
    "    outlier_indices = get_outliers_ind_regression_lin(data, x_col, y_col, threshold=threshold)\n",
    "\n",
    "    # println(\"Outlier Indices Identified: \", outlier_indices)\n",
    "\n",
    "    keep_mask = trues(nrow(data))\n",
    "    \n",
    "    if !isempty(outlier_indices)\n",
    "        keep_mask[outlier_indices] .= false\n",
    "    end\n",
    "\n",
    "    cleaned_data = data[keep_mask, :]\n",
    "    \n",
    "    return cleaned_data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "plot_outliers (generic function with 1 method)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " function plot_outliers(uniqueD)\n",
    " # Step 2: Find and Display Outliers with Regression\n",
    " outliers_indices = get_outliers_ind_regression_lin(uniqueD, :cylindree, :consommation)\n",
    " outliers_regression = get_outliers_regression_lin(uniqueD, outliers_indices)\n",
    "\n",
    " # Step 3: Plot Original Data, Regression Line, and Outliers\n",
    " slope, intercept = linear_regression(uniqueD, :cylindree, :consommation)\n",
    " regression_line_y = slope .* uniqueD.cylindree .+ intercept\n",
    "\n",
    " layer_original = layer(x=uniqueD.cylindree, y=uniqueD.consommation, color=uniqueD.type, Theme(default_color=\"blue\"))\n",
    " layer_linear_regression = layer(x=uniqueD.cylindree, y=regression_line_y, Geom.line, Theme(default_color=\"green\"))\n",
    " layer_regression_outliers = layer(x=outliers_regression.cylindree, y=outliers_regression.consommation, Geom.point, Theme(default_color=\"red\"))\n",
    "\n",
    " \n",
    " display(plot(layer_regression_outliers, layer_original, layer_linear_regression, Guide.xlabel(\"Cylindree\"), Guide.ylabel(\"Consommation\"), Guide.title(\"Original Data with Outliers\")))\n",
    "\n",
    " # Step 4: Remove Outliers Based on Regression Line\n",
    " cleaned_data = remove_outliers_regression_lin(uniqueD, :cylindree, :consommation, threshold=2.5)\n",
    "\n",
    " # Step 5: Plot Cleaned Data with New Regression Line\n",
    " slope_cleaned, intercept_cleaned = linear_regression(cleaned_data, :cylindree, :consommation)\n",
    " regression_line_y_cleaned = slope_cleaned .* cleaned_data.cylindree .+ intercept_cleaned\n",
    "\n",
    "layer_cleaned = layer(x=cleaned_data.cylindree, y=cleaned_data.consommation, color=cleaned_data.type, Theme(default_color=\"blue\"))\n",
    "layer_linear_regression_cleaned = layer(x=cleaned_data.cylindree, y=regression_line_y_cleaned, Geom.line, Theme(default_color=\"green\"))\n",
    "\n",
    "# Display plot for cleaned data\n",
    "display(plot(layer_cleaned, layer_linear_regression_cleaned, \n",
    "             Guide.xlabel(\"Cylindree\"), Guide.ylabel(\"Consommation\"), Guide.title(\"Cleaned Data with Regression Line\")))\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "regression (generic function with 2 methods)"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function regression(standardised_data, trainTestSplitPercentage = 0.2)\n",
    "    training_data, test_data = train_test_split(standardised_data, trainTestSplitPercentage)\n",
    "\n",
    "    X_train =  Matrix(training_data[:, Not(:consommation)])\n",
    "    y_train = training_data[:, :consommation]\n",
    "\n",
    "    beta = X_train \\ y_train\n",
    "\n",
    "    rmseval = 0.0\n",
    "    if trainTestSplitPercentage != 0.0\n",
    "        X_test = Matrix(test_data[:, Not(:consommation)])\n",
    "        y_test = test_data[:, :consommation]\n",
    "        ychap =  X_test * beta\n",
    "        ychap = (ychap .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        y_test = (y_test .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "        rmseval = rmse(y_test, ychap)\n",
    "    end\n",
    "    \n",
    "    return rmseval, beta, training_data, test_data\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "remise_regression (generic function with 1 method)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function remise_regression(beta)\n",
    "    test_data = getStandardEncodedData(testData)\n",
    "    X_test = Matrix(test_data[!,Not(:id)])\n",
    "    ychap =  X_test * beta\n",
    "    # ychap = (ychap .* COMSOMMATION_STD) .+ COMSOMMATION_MEAN\n",
    "    remise(ychap)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consommation for 5.9 cylindree in trainData:\n",
      "[13.8358823529412, 13.8358823529412]\n",
      "[\"type\", \"nombre_cylindres\", \"cylindree\", \"transmission\", \"boite\"]\n",
      "[1, 2, 3, 4, 6, 7, 8, 9, 13, 14, 15, 16, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 40, 41, 43, 44, 46, 47, 50, 51, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 103, 104, 105, 106, 108, 109, 111, 113, 114, 116, 117, 120, 121, 122, 123, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150]\n",
      "[\"type\", \"nombre_cylindres\", \"cylindree\", \"transmission\"]\n",
      "[98, 112, 10, 11, 72, 39, 45, 132, 49]\n",
      "[\"type\", \"nombre_cylindres\", \"cylindree\"]\n",
      "[119, 68, 69, 70, 115, 99, 118, 124, 125, 48]\n",
      "[\"nombre_cylindres\", \"cylindree\"]\n",
      "[107, 52, 42, 110, 12, 88, 17, 18, 19, 20]\n",
      "\u001b[1m150×2 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m id    \u001b[0m\u001b[1m consommation \u001b[0m\n",
      "     │\u001b[90m Int64 \u001b[0m\u001b[90m Float64      \u001b[0m\n",
      "─────┼─────────────────────\n",
      "   1 │     1       8.11069\n",
      "   2 │     2       7.59532\n",
      "   3 │     3       8.66848\n",
      "   4 │     4       8.71148\n",
      "   5 │     5      14.7583\n",
      "   6 │     6      13.8359\n",
      "   7 │     7      13.8359\n",
      "   8 │     8      10.2265\n",
      "   9 │     9      10.9459\n",
      "  10 │    10      15.3451\n",
      "  11 │    11      15.3451\n",
      "  12 │    12      15.6807\n",
      "  13 │    13       9.30079\n",
      "  14 │    14      10.3044\n",
      "  15 │    15       8.11069\n",
      "  16 │    16      11.5738\n",
      "  17 │    17      13.0672\n",
      "  18 │    18      13.0672\n",
      "  19 │    19      13.0672\n",
      "  20 │    20      13.0672\n",
      "  21 │    21      13.8359\n",
      "  22 │    22      13.0672\n",
      "  23 │    23      13.0672\n",
      "  24 │    24      13.8359\n",
      "  25 │    25      13.0672\n",
      "  26 │    26      14.7006\n",
      "  27 │    27      13.0672\n",
      "  28 │    28      14.7006\n",
      "  29 │    29      12.6546\n",
      "  30 │    30      10.5223\n",
      "  31 │    31      11.9668\n",
      "  32 │    32       8.66848\n",
      "  33 │    33      10.3953\n",
      "  34 │    34      11.9668\n",
      "  35 │    35       9.04654\n",
      "  36 │    36       7.58742\n",
      "  37 │    37      10.5223\n",
      "  38 │    38      10.5223\n",
      "  39 │    39       8.7731\n",
      "  40 │    40       9.04654\n",
      "  41 │    41      13.0672\n",
      "  42 │    42      11.1424\n",
      "  43 │    43      10.1294\n",
      "  44 │    44       7.58567\n",
      "  45 │    45       8.7731\n",
      "  46 │    46      11.2107\n",
      "  47 │    47      10.3953\n",
      "  48 │    48      11.5354\n",
      "  49 │    49       7.4362\n",
      "  50 │    50      14.4124\n",
      "  51 │    51      12.3795\n",
      "  52 │    52      10.9897\n",
      "  53 │    53       4.90021\n",
      "  54 │    54      13.0672\n",
      "  55 │    55      10.5223\n",
      "  56 │    56      10.5223\n",
      "  57 │    57      11.2005\n",
      "  58 │    58      12.838\n",
      "  59 │    59       8.96277\n",
      "  60 │    60       8.71148\n",
      "  61 │    61       8.87901\n",
      "  62 │    62       9.61229\n",
      "  63 │    63      10.0135\n",
      "  64 │    64      10.0135\n",
      "  65 │    65       8.79525\n",
      "  66 │    66      11.0378\n",
      "  67 │    67      11.0378\n",
      "  68 │    68      12.9347\n",
      "  69 │    69      12.9347\n",
      "  70 │    70      12.9347\n",
      "  71 │    71      10.2459\n",
      "  72 │    72      12.121\n",
      "  73 │    73      10.2459\n",
      "  74 │    74      10.1924\n",
      "  75 │    75      10.2459\n",
      "  76 │    76      12.3795\n",
      "  77 │    77      15.6807\n",
      "  78 │    78      15.6807\n",
      "  79 │    79      10.3953\n",
      "  80 │    80      11.9668\n",
      "  81 │    81      11.7801\n",
      "  82 │    82       9.30079\n",
      "  83 │    83       9.64327\n",
      "  84 │    84       8.71148\n",
      "  85 │    85       8.71148\n",
      "  86 │    86       8.78864\n",
      "  87 │    87      10.1294\n",
      "  88 │    88      10.4982\n",
      "  89 │    89       8.12035\n",
      "  90 │    90       8.11713\n",
      "  91 │    91      10.2265\n",
      "  92 │    92      13.1077\n",
      "  93 │    93       8.18793\n",
      "  94 │    94       8.12035\n",
      "  95 │    95       8.12035\n",
      "  96 │    96       4.52327\n",
      "  97 │    97       4.52327\n",
      "  98 │    98       8.8407\n",
      "  99 │    99      11.2005\n",
      " 100 │   100      10.1294\n",
      " 101 │   101       8.71148\n",
      " 102 │   102      11.4041\n",
      " 103 │   103       9.04654\n",
      " 104 │   104       8.78864\n",
      " 105 │   105       8.40036\n",
      " 106 │   106       8.79525\n",
      " 107 │   107       9.09666\n",
      " 108 │   108      10.1294\n",
      " 109 │   109      11.2005\n",
      " 110 │   110      11.1424\n",
      " 111 │   111       8.78864\n",
      " 112 │   112       8.8407\n",
      " 113 │   113       8.11069\n",
      " 114 │   114       9.30079\n",
      " 115 │   115       8.40036\n",
      " 116 │   116       8.75935\n",
      " 117 │   117       7.93627\n",
      " 118 │   118      10.6914\n",
      " 119 │   119      11.2005\n",
      " 120 │   120       9.80042\n",
      " 121 │   121       9.4084\n",
      " 122 │   122      10.2265\n",
      " 123 │   123       8.71148\n",
      " 124 │   124       8.87901\n",
      " 125 │   125       8.87901\n",
      " 126 │   126      10.9459\n",
      " 127 │   127       7.53425\n",
      " 128 │   128      10.1294\n",
      " 129 │   129      12.9347\n",
      " 130 │   130       8.75935\n",
      " 131 │   131       8.40036\n",
      " 132 │   132       8.7731\n",
      " 133 │   133       7.53425\n",
      " 134 │   134      14.7006\n",
      " 135 │   135      10.1294\n",
      " 136 │   136       9.53164\n",
      " 137 │   137      10.9459\n",
      " 138 │   138       7.53425\n",
      " 139 │   139       7.35031\n",
      " 140 │   140      11.7605\n",
      " 141 │   141      12.6546\n",
      " 142 │   142      10.1294\n",
      " 143 │   143       9.30079\n",
      " 144 │   144       7.53425\n",
      " 145 │   145       8.60777\n",
      " 146 │   146       8.87901\n",
      " 147 │   147      11.7605\n",
      " 148 │   148      10.9173\n",
      " 149 │   149       7.58742\n",
      " 150 │   150       7.93627\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"./soumissions_potentielles/benchmark_2024-12-02_16-14-17.csv\""
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNS_TO_COMPARE_1 = [\"type\", \"nombre_cylindres\", \"cylindree\", \"transmission\", \"boite\"]\n",
    "COLUMNS_TO_COMPARE_2 = [\"type\", \"nombre_cylindres\", \"cylindree\", \"transmission\"]\n",
    "COLUMNS_TO_COMPARE_3 = [\"type\", \"nombre_cylindres\", \"cylindree\"]\n",
    "COLUMNS_TO_COMPARE_4 = [\"nombre_cylindres\", \"cylindree\"]\n",
    "COLUMNS_TO_COMPARE_5 = [\"cylindree\"]\n",
    "\n",
    "function main(testData)\n",
    "    # println(find_duplicates(trainData))\n",
    "\n",
    "    println(\"Consommation for 5.9 cylindree in trainData:\")\n",
    "    println(trainData[trainData.cylindree .== 5.7, :consommation])\n",
    "    # print(trainData)\n",
    "\n",
    "    # Step 1: Get Unique Data\n",
    "    uniqueD = get_unique_data(trainData, COLUMNS_TO_COMPARE_1)\n",
    "    # print(uniqueD)\n",
    "    # println(uniqueD)\n",
    "\n",
    "    pairs = find_pairs(uniqueD, testData, COLUMNS_TO_COMPARE_1)\n",
    "    pairs = select(pairs, [:id, :consommation])\n",
    "\n",
    "    # print(pairs)\n",
    "\n",
    "    testData = filter(row -> !(row.id in pairs.id), testData)\n",
    "\n",
    "    # print(testData)\n",
    "\n",
    "    uniqueD = get_unique_data(uniqueD, COLUMNS_TO_COMPARE_2)\n",
    "\n",
    "    pairs_2 = find_pairs(uniqueD, testData, COLUMNS_TO_COMPARE_2)\n",
    "    pairs_2 = select(pairs_2, [:id, :consommation])\n",
    "\n",
    "    pairs_official = pairs\n",
    "\n",
    "    pairs = vcat(pairs, pairs_2)\n",
    "\n",
    "    testData = filter(row -> !(row.id in pairs.id), testData)\n",
    "\n",
    "\n",
    "    uniqueD = get_unique_data(uniqueD, COLUMNS_TO_COMPARE_3)\n",
    "\n",
    "    pairs_3 = find_pairs(uniqueD, testData, COLUMNS_TO_COMPARE_3)\n",
    "    pairs_3 = select(pairs_3, [:id, :consommation])\n",
    "\n",
    "\n",
    "    pairs_official = vcat(pairs_official, pairs_3)\n",
    "    pairs = vcat(pairs, pairs_3)\n",
    "\n",
    "    testData = filter(row -> !(row.id in pairs.id), testData)\n",
    "\n",
    "    uniqueD = get_unique_data(uniqueD, COLUMNS_TO_COMPARE_4)\n",
    "\n",
    "    \n",
    "\n",
    "    pairs_4 = find_pairs(uniqueD, testData, COLUMNS_TO_COMPARE_4)\n",
    "    pairs_4 = select(pairs_4, [:id, :consommation])\n",
    "\n",
    "    pairs_official = vcat(pairs_official, pairs_4)\n",
    "    pairs = vcat(pairs, pairs_4)\n",
    "\n",
    "    testData = filter(row -> !(row.id in pairs.id), testData)\n",
    "\n",
    "    average= (15.6806666666667 + 13.8358823529412)/2\n",
    "\n",
    "    pairs_5 = DataFrame(id=5, consommation=average)\n",
    "\n",
    "    pairs_official = vcat(pairs_official, pairs_5)\n",
    "    pairs = vcat(pairs, pairs_5)\n",
    "    testData = filter(row -> !(row.id in pairs.id), testData)\n",
    "    # print(testData)\n",
    "\n",
    "    # vcat(pairs_1, pairs_2, pairs_3, pairs_4, pairs_5)\n",
    "\n",
    "    # println(pairs_2.id)\n",
    "\n",
    "    data_1 = CSV.read(\"./soumissions_officielles/soumission_7/benchmark7.csv\", DataFrame)\n",
    "\n",
    "    rows_in_data_1 = filter(row -> row.id in pairs_2.id, data_1)\n",
    "    # println(rows_in_data_1)\n",
    "\n",
    "\n",
    "    pairs_official = vcat(pairs_official, rows_in_data_1)\n",
    "\n",
    "\n",
    "    sort!(pairs_official, :id)\n",
    "\n",
    "    # println(pairs_official)\n",
    "\n",
    "    # print(pairs)\n",
    "\n",
    "    format_file(pairs_official)\n",
    "\n",
    "    # uniqueD = remove_outliers_regression_lin(uniqueD, :cylindree, :consommation, threshold=2.5)\n",
    "\n",
    "    # unique_standard = getStandardEncodedData(uniqueD)\n",
    "    # predictStandard = getStandardEncodedData(testData)\n",
    "    # evaluate_rmse(uniqueD)\n",
    "\n",
    "    # println(uniqueD)\n",
    "    # println(predictStandard)\n",
    "\n",
    "\n",
    "    # format_file(predict_with_dups(unique_standard, predictStandard, uniqueD, testData))\n",
    "\n",
    "\n",
    "    # predict_with_dups(unique_standard, predictStandard, uniqueD, testData)\n",
    "    # format_file(predict_with_dups(uniqueD, testData))\n",
    " \n",
    "end\n",
    "main(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for type in unique(trainData.type)\n",
    "#     println(type)\n",
    "#     data_type = trainData[trainData.type .== type, :]\n",
    "#     println(combine(groupby(data_type, :transmission), :consommation => mean, :volume_gaz => mean, nrow => :nrow))\n",
    "#     println()\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for type in unique(trainData.type)\n",
    "#     println(type)\n",
    "#     data_type = trainData[trainData.type .== type, :]\n",
    "#     display(plot(x=data_type.volume_gaz, y=data_type.consommation))\n",
    "#     println()\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration des données"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.5",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
